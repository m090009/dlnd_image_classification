{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Image Classification\n",
    "In this project, you'll classify images from the [CIFAR-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html).  The dataset consists of airplanes, dogs, cats, and other objects. You'll preprocess the images, then train a convolutional neural network on all the samples. The images need to be normalized and the labels need to be one-hot encoded.  You'll get to apply what you learned and build a convolutional, max pooling, dropout, and fully connected layers.  At the end, you'll get to see your neural network's predictions on the sample images.\n",
    "## Get the Data\n",
    "Run the following cell to download the [CIFAR-10 dataset for python](https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CIFAR-10 Dataset: 171MB [08:34, 331KB/s]                                                                                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files found!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm\n",
    "import problem_unittests as tests\n",
    "import tarfile\n",
    "\n",
    "cifar10_dataset_folder_path = 'cifar-10-batches-py'\n",
    "\n",
    "# Use Floyd's cifar-10 dataset if present\n",
    "floyd_cifar10_location = '/cifar/cifar-10-python.tar.gz'\n",
    "if isfile(floyd_cifar10_location):\n",
    "    tar_gz_path = floyd_cifar10_location\n",
    "else:\n",
    "    tar_gz_path = 'cifar-10-python.tar.gz'\n",
    "\n",
    "class DLProgress(tqdm):\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "\n",
    "if not isfile(tar_gz_path):\n",
    "    with DLProgress(unit='B', unit_scale=True, miniters=1, desc='CIFAR-10 Dataset') as pbar:\n",
    "        urlretrieve(\n",
    "            'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz',\n",
    "            tar_gz_path,\n",
    "            pbar.hook)\n",
    "\n",
    "if not isdir(cifar10_dataset_folder_path):\n",
    "    with tarfile.open(tar_gz_path) as tar:\n",
    "        tar.extractall()\n",
    "        tar.close()\n",
    "\n",
    "\n",
    "tests.test_folder_path(cifar10_dataset_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the Data\n",
    "The dataset is broken into batches to prevent your machine from running out of memory.  The CIFAR-10 dataset consists of 5 batches, named `data_batch_1`, `data_batch_2`, etc.. Each batch contains the labels and images that are one of the following:\n",
    "* airplane\n",
    "* automobile\n",
    "* bird\n",
    "* cat\n",
    "* deer\n",
    "* dog\n",
    "* frog\n",
    "* horse\n",
    "* ship\n",
    "* truck\n",
    "\n",
    "Understanding a dataset is part of making predictions on the data.  Play around with the code cell below by changing the `batch_id` and `sample_id`. The `batch_id` is the id for a batch (1-5). The `sample_id` is the id for a image and label pair in the batch.\n",
    "\n",
    "Ask yourself \"What are all possible labels?\", \"What is the range of values for the image data?\", \"Are the labels in order or random?\".  Answers to questions like these will help you preprocess the data and end up with better predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stats of batch 3:\n",
      "Samples: 10000\n",
      "Label Counts: {0: 994, 1: 1042, 2: 965, 3: 997, 4: 990, 5: 1029, 6: 978, 7: 1015, 8: 961, 9: 1029}\n",
      "First 20 Labels: [8, 5, 0, 6, 9, 2, 8, 3, 6, 2, 7, 4, 6, 9, 0, 0, 7, 3, 7, 2]\n",
      "\n",
      "Example of Image 4:\n",
      "Image - Min Value: 10 Max Value: 255\n",
      "Image - Shape: (32, 32, 3)\n",
      "Label - Label Id: 9 Name: truck\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAH0CAYAAADVH+85AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1e726206cc0>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import helper\n",
    "import numpy as np\n",
    "\n",
    "# Explore the dataset\n",
    "batch_id = 3\n",
    "sample_id = 4\n",
    "helper.display_stats(cifar10_dataset_folder_path, batch_id, sample_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Preprocess Functions\n",
    "### Normalize\n",
    "In the cell below, implement the `normalize` function to take in image data, `x`, and return it as a normalized Numpy array. The values should be in the range of 0 to 1, inclusive.  The return object should be the same shape as `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def normalize(x):\n",
    "    \"\"\"\n",
    "    Normalize a list of sample image data in the range of 0 to 1\n",
    "    : x: List of image data.  The image shape is (32, 32, 3)\n",
    "    : return: Numpy array of normalize data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return (x - x.min()) / (x.max() - x.min())\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_normalize(normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encode\n",
    "Just like the previous code cell, you'll be implementing a function for preprocessing.  This time, you'll implement the `one_hot_encode` function. The input, `x`, are a list of labels.  Implement the function to return the list of labels as One-Hot encoded Numpy array.  The possible values for labels are 0 to 9. The one-hot encoding function should return the same encoding for each value between each call to `one_hot_encode`.  Make sure to save the map of encodings outside the function.\n",
    "\n",
    "Hint: Don't reinvent the wheel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "one_hot_encodings = []\n",
    "def one_hot_encode(x):\n",
    "    \"\"\"\n",
    "    One hot encode a list of sample labels. Return a one-hot encoded vector for each label.\n",
    "    : x: List of sample Labels\n",
    "    : return: Numpy array of one-hot encoded labels\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    encoder = LabelBinarizer()\n",
    "    encoder.fit(np.array([0,1,2,3,4,5,6,7,8,9]))\n",
    "    one_hot = encoder.transform(x)\n",
    "    one_hot_encodings.append(one_hot)\n",
    "    return one_hot\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_one_hot_encode(one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomize Data\n",
    "As you saw from exploring the data above, the order of the samples are randomized.  It doesn't hurt to randomize it again, but you don't need to for this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess all the data and save it\n",
    "Running the code cell below will preprocess all the CIFAR-10 data and save it to file. The code below also uses 10% of the training data for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "# Preprocess Training, Validation, and Testing Data\n",
    "helper.preprocess_and_save_data(cifar10_dataset_folder_path, normalize, one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Point\n",
    "This is your first checkpoint.  If you ever decide to come back to this notebook or have to restart the notebook, you can start from here.  The preprocessed data has been saved to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import pickle\n",
    "import problem_unittests as tests\n",
    "import helper\n",
    "\n",
    "# Load the Preprocessed Validation data\n",
    "valid_features, valid_labels = pickle.load(open('preprocess_validation.p', mode='rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the network\n",
    "For the neural network, you'll build each layer into a function.  Most of the code you've seen has been outside of functions. To test your code more thoroughly, we require that you put each layer in a function.  This allows us to give you better feedback and test for simple mistakes using our unittests before you submit your project.\n",
    "\n",
    ">**Note:** If you're finding it hard to dedicate enough time for this course each week, we've provided a small shortcut to this part of the project. In the next couple of problems, you'll have the option to use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages to build each layer, except the layers you build in the \"Convolutional and Max Pooling Layer\" section.  TF Layers is similar to Keras's and TFLearn's abstraction to layers, so it's easy to pickup.\n",
    "\n",
    ">However, if you would like to get the most out of this course, try to solve all the problems _without_ using anything from the TF Layers packages. You **can** still use classes from other packages that happen to have the same name as ones you find in TF Layers! For example, instead of using the TF Layers version of the `conv2d` class, [tf.layers.conv2d](https://www.tensorflow.org/api_docs/python/tf/layers/conv2d), you would want to use the TF Neural Network version of `conv2d`, [tf.nn.conv2d](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d). \n",
    "\n",
    "Let's begin!\n",
    "\n",
    "### Input\n",
    "The neural network needs to read the image data, one-hot encoded labels, and dropout keep probability. Implement the following functions\n",
    "* Implement `neural_net_image_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `image_shape` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"x\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "* Implement `neural_net_label_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `n_classes` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"y\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "* Implement `neural_net_keep_prob_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) for dropout keep probability.\n",
    " * Name the TensorFlow placeholder \"keep_prob\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "\n",
    "These names will be used at the end of the project to load your saved model.\n",
    "\n",
    "Note: `None` for shapes in TensorFlow allow for a dynamic size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Input Tests Passed.\n",
      "Label Input Tests Passed.\n",
      "Keep Prob Tests Passed.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def neural_net_image_input(image_shape):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of image input\n",
    "    : image_shape: Shape of the images\n",
    "    : return: Tensor for image input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "#     print(image_shape)\n",
    "    return tf.placeholder(tf.float32, shape= (None, *image_shape), name= \"x\")\n",
    "\n",
    "\n",
    "def neural_net_label_input(n_classes):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of label input\n",
    "    : n_classes: Number of classes\n",
    "    : return: Tensor for label input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "#     print(n_classes)\n",
    "    return tf.placeholder(tf.float32, shape = (None, n_classes), name = \"y\")\n",
    "\n",
    "\n",
    "def neural_net_keep_prob_input():\n",
    "    \"\"\"\n",
    "    Return a Tensor for keep probability\n",
    "    : return: Tensor for keep probability.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32, name = \"keep_prob\")\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tf.reset_default_graph()\n",
    "tests.test_nn_image_inputs(neural_net_image_input)\n",
    "tests.test_nn_label_inputs(neural_net_label_input)\n",
    "tests.test_nn_keep_prob_inputs(neural_net_keep_prob_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution and Max Pooling Layer\n",
    "Convolution layers have a lot of success with images. For this code cell, you should implement the function `conv2d_maxpool` to apply convolution then max pooling:\n",
    "* Create the weight and bias using `conv_ksize`, `conv_num_outputs` and the shape of `x_tensor`.\n",
    "* Apply a convolution to `x_tensor` using weight and `conv_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    "* Add bias\n",
    "* Add a nonlinear activation to the convolution.\n",
    "* Apply Max Pooling using `pool_ksize` and `pool_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    "\n",
    "**Note:** You **can't** use [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) for **this** layer, but you can still use TensorFlow's [Neural Network](https://www.tensorflow.org/api_docs/python/tf/nn) package. You may still use the shortcut option for all the **other** layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=(2, 2, 5, 10) dtype=float32_ref>\n",
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides):\n",
    "    \"\"\"\n",
    "    Apply convolution then max pooling to x_tensor\n",
    "    :param x_tensor: TensorFlow Tensor\n",
    "    :param conv_num_outputs: Number of outputs for the convolutional layer\n",
    "    :param conv_ksize: kernal size 2-D Tuple for the convolutional layer\n",
    "    :param conv_strides: Stride 2-D Tuple for convolution\n",
    "    :param pool_ksize: kernal size 2-D Tuple for pool\n",
    "    :param pool_strides: Stride 2-D Tuple for pool\n",
    "    : return: A tensor that represents convolution and max pooling of x_tensor\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    \n",
    "    # Create the weight and bias using conv_ksize, conv_num_outputs and the shape of x_tensor\n",
    "    \n",
    "    weight = tf.Variable(tf.truncated_normal([conv_ksize[0], conv_ksize[1], int(x_tensor.shape[3]) , conv_num_outputs], stddev = 0.1))\n",
    "    bias = tf.Variable(tf.zeros(conv_num_outputs))\n",
    "    print(weight)\n",
    "    # Apply a convolution to x_tensor using weight and conv_strides\n",
    "    conv_layer = tf.nn.conv2d(x_tensor, weight, strides = [1, conv_strides[0], conv_strides[1], 1], padding = \"SAME\")\n",
    "    # Add bias     \n",
    "    conv_layer += bias\n",
    "    # Add non-linear activation \n",
    "    conv_layer = tf.nn.relu(conv_layer)\n",
    "    # Apply Max Pooling using pool_ksize and pool_strides\n",
    "#     print('\\nStride : {} '.format(conv_strides[0]))\n",
    "    conv_layer = tf.nn.max_pool(conv_layer\n",
    "                              , ksize = [1, pool_ksize[0], pool_ksize[1], 1]\n",
    "                              , strides = [1, pool_strides[0], pool_strides[1], 1]\n",
    "                              , padding = \"SAME\") \n",
    "    return conv_layer\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_con_pool(conv2d_maxpool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flatten Layer\n",
    "Implement the `flatten` function to change the dimension of `x_tensor` from a 4-D tensor to a 2-D tensor.  The output should be the shape (*Batch Size*, *Flattened Image Size*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def flatten(x_tensor):\n",
    "    \"\"\"\n",
    "    Flatten x_tensor to (Batch Size, Flattened Image Size)\n",
    "    : x_tensor: A tensor of size (Batch Size, ...), where ... are the image dimensions.\n",
    "    : return: A tensor of size (Batch Size, Flattened Image Size).\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    flattened_input = tf.reshape(x_tensor\n",
    "                                 , (tf.shape(x_tensor)[0], x_tensor.shape[1] * x_tensor.shape[2] * x_tensor.shape[3]))\n",
    "    return flattened_input\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_flatten(flatten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully-Connected Layer\n",
    "Implement the `fully_conn` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def fully_conn(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a fully connected layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    weight = tf.Variable(tf.truncated_normal([ int(x_tensor.shape[1]), num_outputs], stddev = 0.1))\n",
    "    bias = tf.Variable(tf.zeros([num_outputs]))\n",
    "    connected_layer = tf.add(tf.matmul(x_tensor, weight), bias)\n",
    "    connected_layer = tf.nn.relu(connected_layer)\n",
    "    \n",
    "    \n",
    "    return connected_layer\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_fully_conn(fully_conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Layer\n",
    "Implement the `output` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages.\n",
    "\n",
    "**Note:** Activation, softmax, or cross entropy should **not** be applied to this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def output(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a output layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    weight = tf.Variable(tf.truncated_normal([ int(x_tensor.shape[1]), num_outputs], stddev = 0.1))\n",
    "    bias = tf.Variable(tf.zeros([num_outputs]))\n",
    "    output_layer = tf.add(tf.matmul(x_tensor, weight), bias)\n",
    "    return output_layer\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_output(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Convolutional Model\n",
    "Implement the function `conv_net` to create a convolutional neural network model. The function takes in a batch of images, `x`, and outputs logits.  Use the layers you created above to create this model:\n",
    "\n",
    "* Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "* Apply a Flatten Layer\n",
    "* Apply 1, 2, or 3 Fully Connected Layers\n",
    "* Apply an Output Layer\n",
    "* Return the output\n",
    "* Apply [TensorFlow's Dropout](https://www.tensorflow.org/api_docs/python/tf/nn/dropout) to one or more layers in the model using `keep_prob`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=(3, 3, 3, 16) dtype=float32_ref>\n",
      "<tf.Variable 'Variable_2:0' shape=(3, 3, 16, 32) dtype=float32_ref>\n",
      "<tf.Variable 'Variable_4:0' shape=(3, 3, 32, 64) dtype=float32_ref>\n",
      "(?, 64)\n",
      "WARNING:tensorflow:From <ipython-input-7-a84e47e6c363>:81: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n",
      "<tf.Variable 'Variable_10:0' shape=(3, 3, 3, 16) dtype=float32_ref>\n",
      "<tf.Variable 'Variable_12:0' shape=(3, 3, 16, 32) dtype=float32_ref>\n",
      "<tf.Variable 'Variable_14:0' shape=(3, 3, 32, 64) dtype=float32_ref>\n",
      "(?, 64)\n",
      "Neural Network Built!\n"
     ]
    }
   ],
   "source": [
    "def conv_net(x, keep_prob):\n",
    "    \"\"\"\n",
    "    Create a convolutional neural network model\n",
    "    : x: Placeholder tensor that holds image data.\n",
    "    : keep_prob: Placeholder tensor that hold dropout keep probability.\n",
    "    : return: Tensor that represents logits\n",
    "    \"\"\"\n",
    "    # TODO: Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "    #    Play around with different number of outputs, kernel size and stride\n",
    "    # Function Definition from Above:\n",
    "    #    conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    conv_num_outputs = 16\n",
    "    conv_num_outputs_2 = 32 \n",
    "    conv_num_outputs_3 = 32\n",
    "    conv_ksize = (3,3)\n",
    "    conv_strides = (1,1)\n",
    "    pool_ksize = (2,2)\n",
    "    pool_strides = (2,2)\n",
    "    num_outputs = 16\n",
    "    n_classes = 10\n",
    "    \n",
    "    conv_layer = conv2d_maxpool(x, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    \n",
    "    conv_layer_2 = conv2d_maxpool(conv_layer, conv_num_outputs_2, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    \n",
    "    conv_layer_3 = conv2d_maxpool(conv_layer_2, conv_num_outputs_3*2, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    \n",
    "#     conv_layer_4 = conv2d_maxpool(conv_layer_3, conv_num_outputs_3*2, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    # TODO: Apply a Flatten Layer\n",
    "    # Function Definition from Above:\n",
    "    #   flatten(x_tensor)\n",
    "    flattened = flatten(conv_layer_3)\n",
    "\n",
    "    # TODO: Apply 1, 2, or 3 Fully Connected Layers\n",
    "    #    Play around with different number of outputs\n",
    "    # Function Definition from Above:\n",
    "    #   fully_conn(x_tensor, num_outputs)\n",
    "    connected_layer = flattened#fully_conn(flattened, conv_num_outputs_3)\n",
    "#     connected_layer = tf.nn.dropout(connected_layer, keep_prob)\n",
    "#     print(connected_layer.shape)\n",
    "    \n",
    "    \n",
    "    connected_layer_2 = fully_conn(connected_layer, conv_num_outputs_3*2)\n",
    "    connected_layer_2 = tf.nn.dropout(connected_layer_2, keep_prob)\n",
    "    print(connected_layer_2.shape)\n",
    "#     connected_layer_2 = fully_conn(connected_layer, 20)\n",
    "    \n",
    "    # TODO: Apply an Output Layer\n",
    "    #    Set this to the number of classes\n",
    "    # Function Definition from Above:\n",
    "    #   output(x_tensor, num_outputs)\n",
    "    output_layer = output(connected_layer_2, n_classes)\n",
    "    \n",
    "    # TODO: return output\n",
    "    return output_layer\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "\n",
    "##############################\n",
    "## Build the Neural Network ##\n",
    "##############################\n",
    "\n",
    "# Remove previous weights, bias, inputs, etc..\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Inputs\n",
    "x = neural_net_image_input((32, 32, 3))\n",
    "y = neural_net_label_input(10)\n",
    "keep_prob = neural_net_keep_prob_input()\n",
    "\n",
    "# Model\n",
    "logits = conv_net(x, keep_prob)\n",
    "\n",
    "# Name logits Tensor, so that is can be loaded from disk after training\n",
    "logits = tf.identity(logits, name='logits')\n",
    "\n",
    "# Loss and Optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "\n",
    "\n",
    "tests.test_conv_net(conv_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Neural Network\n",
    "### Single Optimization\n",
    "Implement the function `train_neural_network` to do a single optimization.  The optimization should use `optimizer` to optimize in `session` with a `feed_dict` of the following:\n",
    "* `x` for image input\n",
    "* `y` for labels\n",
    "* `keep_prob` for keep probability for dropout\n",
    "\n",
    "This function will be called for each batch, so `tf.global_variables_initializer()` has already been called.\n",
    "\n",
    "Note: Nothing needs to be returned. This function is only optimizing the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def train_neural_network(session, optimizer, keep_probability, feature_batch, label_batch):\n",
    "    \"\"\"\n",
    "    Optimize the session on a batch of images and labels\n",
    "    : session: Current TensorFlow session\n",
    "    : optimizer: TensorFlow optimizer function\n",
    "    : keep_probability: keep probability\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    session.run(optimizer, feed_dict={\n",
    "                x : feature_batch,\n",
    "                y : label_batch,\n",
    "                keep_prob : keep_probability})\n",
    "    pass\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_train_nn(train_neural_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show Stats\n",
    "Implement the function `print_stats` to print loss and validation accuracy.  Use the global variables `valid_features` and `valid_labels` to calculate validation accuracy.  Use a keep probability of `1.0` to calculate the loss and validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_stats(session, feature_batch, label_batch, cost, accuracy):\n",
    "    \"\"\"\n",
    "    Print information about loss and validation accuracy\n",
    "    : session: Current TensorFlow session\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    : cost: TensorFlow cost function\n",
    "    : accuracy: TensorFlow accuracy function\n",
    "    \"\"\"\n",
    "    my_keep_prob = 1.0\n",
    "    # TODO: Implement Function\n",
    "    loss = session.run(cost, feed_dict = { x: feature_batch \n",
    "                                          ,y: label_batch\n",
    "                                          ,keep_prob: my_keep_prob})\n",
    "    \n",
    "    my_accuracy = session.run(accuracy, feed_dict = { x: feature_batch \n",
    "                                          ,y: label_batch\n",
    "                                          ,keep_prob: my_keep_prob})\n",
    "    \n",
    "    val_accuracy = session.run(accuracy, feed_dict = { x: valid_features\n",
    "                                                  ,y: valid_labels \n",
    "                                                  ,keep_prob: my_keep_prob})\n",
    "    \n",
    "    print('\\nLoss: {} accuracy: {}'.format(loss, my_accuracy))\n",
    "    print('\\nValidation accuracy: {}'.format(val_accuracy))\n",
    "    return loss, my_accuracy, val_accuracy\n",
    "    \n",
    "    \n",
    "# Define loss and optimizer\n",
    "# cost = tf.reduce_mean(\\\n",
    "#     tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "# optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\\\n",
    "#     .minimize(cost)\n",
    "\n",
    "# # Accuracy\n",
    "# correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "# accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "#      loss = sess.run(cost, feed_dict={\n",
    "#                 x: batch_x,\n",
    "#                 y: batch_y,\n",
    "#                 keep_prob: 1.})\n",
    "#      valid_acc = sess.run(accuracy, feed_dict={\n",
    "#                 x: mnist.validation.images[:test_valid_size],\n",
    "#                 y: mnist.validation.labels[:test_valid_size],\n",
    "#                 keep_prob: 1.})\n",
    "\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters\n",
    "Tune the following parameters:\n",
    "* Set `epochs` to the number of iterations until the network stops learning or start overfitting\n",
    "* Set `batch_size` to the highest number that your machine has memory for.  Most people set them to common sizes of memory:\n",
    " * 64\n",
    " * 128\n",
    " * 256\n",
    " * ...\n",
    "* Set `keep_probability` to the probability of keeping a node using dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Tune Parameters\n",
    "epochs = 100\n",
    "batch_size = 1024\n",
    "keep_probability = 0.75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on a Single CIFAR-10 Batch\n",
    "Instead of training the neural network on all the CIFAR-10 batches of data, let's use a single batch. This should save time while you iterate on the model to get a better accuracy.  Once the final validation accuracy is 50% or greater, run the model on all the data in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the Training on a Single Batch...\n",
      "Epoch  1, CIFAR-10 Batch 1:  \n",
      "Loss: 2.242877960205078 accuracy: 0.22648514807224274\n",
      "\n",
      "Validation accuracy: 0.19679999351501465\n",
      "Epoch  2, CIFAR-10 Batch 1:  \n",
      "Loss: 2.087704658508301 accuracy: 0.2698019742965698\n",
      "\n",
      "Validation accuracy: 0.26339998841285706\n",
      "Epoch  3, CIFAR-10 Batch 1:  \n",
      "Loss: 1.9766448736190796 accuracy: 0.30074256658554077\n",
      "\n",
      "Validation accuracy: 0.28220000863075256\n",
      "Epoch  4, CIFAR-10 Batch 1:  \n",
      "Loss: 1.8792243003845215 accuracy: 0.35148516297340393\n",
      "\n",
      "Validation accuracy: 0.3555999994277954\n",
      "Epoch  5, CIFAR-10 Batch 1:  \n",
      "Loss: 1.797408938407898 accuracy: 0.3836633563041687\n",
      "\n",
      "Validation accuracy: 0.36800000071525574\n",
      "Epoch  6, CIFAR-10 Batch 1:  \n",
      "Loss: 1.7306742668151855 accuracy: 0.40594059228897095\n",
      "\n",
      "Validation accuracy: 0.39739999175071716\n",
      "Epoch  7, CIFAR-10 Batch 1:  \n",
      "Loss: 1.6784979104995728 accuracy: 0.4368811845779419\n",
      "\n",
      "Validation accuracy: 0.4174000024795532\n",
      "Epoch  8, CIFAR-10 Batch 1:  \n",
      "Loss: 1.6327965259552002 accuracy: 0.448019802570343\n",
      "\n",
      "Validation accuracy: 0.426800012588501\n",
      "Epoch  9, CIFAR-10 Batch 1:  \n",
      "Loss: 1.5949677228927612 accuracy: 0.45049506425857544\n",
      "\n",
      "Validation accuracy: 0.4375999867916107\n",
      "Epoch 10, CIFAR-10 Batch 1:  \n",
      "Loss: 1.5633304119110107 accuracy: 0.4628712832927704\n",
      "\n",
      "Validation accuracy: 0.44620001316070557\n",
      "Epoch 11, CIFAR-10 Batch 1:  \n",
      "Loss: 1.5405068397521973 accuracy: 0.4801980257034302\n",
      "\n",
      "Validation accuracy: 0.44519999623298645\n",
      "Epoch 12, CIFAR-10 Batch 1:  \n",
      "Loss: 1.5134823322296143 accuracy: 0.4752475321292877\n",
      "\n",
      "Validation accuracy: 0.45019999146461487\n",
      "Epoch 13, CIFAR-10 Batch 1:  \n",
      "Loss: 1.4943469762802124 accuracy: 0.4752475321292877\n",
      "\n",
      "Validation accuracy: 0.459199994802475\n",
      "Epoch 14, CIFAR-10 Batch 1:  \n",
      "Loss: 1.4721033573150635 accuracy: 0.4839108884334564\n",
      "\n",
      "Validation accuracy: 0.4625999927520752\n",
      "Epoch 15, CIFAR-10 Batch 1:  \n",
      "Loss: 1.4383320808410645 accuracy: 0.4913366436958313\n",
      "\n",
      "Validation accuracy: 0.47620001435279846\n",
      "Epoch 16, CIFAR-10 Batch 1:  \n",
      "Loss: 1.4001245498657227 accuracy: 0.5074257254600525\n",
      "\n",
      "Validation accuracy: 0.48159998655319214\n",
      "Epoch 17, CIFAR-10 Batch 1:  \n",
      "Loss: 1.3775147199630737 accuracy: 0.5272276997566223\n",
      "\n",
      "Validation accuracy: 0.492000013589859\n",
      "Epoch 18, CIFAR-10 Batch 1:  \n",
      "Loss: 1.378652572631836 accuracy: 0.5222772359848022\n",
      "\n",
      "Validation accuracy: 0.49000000953674316\n",
      "Epoch 19, CIFAR-10 Batch 1:  \n",
      "Loss: 1.3670722246170044 accuracy: 0.5235148668289185\n",
      "\n",
      "Validation accuracy: 0.48660001158714294\n",
      "Epoch 20, CIFAR-10 Batch 1:  \n",
      "Loss: 1.3452463150024414 accuracy: 0.5297029614448547\n",
      "\n",
      "Validation accuracy: 0.48660001158714294\n",
      "Epoch 21, CIFAR-10 Batch 1:  \n",
      "Loss: 1.3058383464813232 accuracy: 0.530940592288971\n",
      "\n",
      "Validation accuracy: 0.5117999911308289\n",
      "Epoch 22, CIFAR-10 Batch 1:  \n",
      "Loss: 1.2923555374145508 accuracy: 0.5507425665855408\n",
      "\n",
      "Validation accuracy: 0.5185999870300293\n",
      "Epoch 23, CIFAR-10 Batch 1:  \n",
      "Loss: 1.2894915342330933 accuracy: 0.5420792102813721\n",
      "\n",
      "Validation accuracy: 0.5123999714851379\n",
      "Epoch 24, CIFAR-10 Batch 1:  \n",
      "Loss: 1.2588484287261963 accuracy: 0.5680692791938782\n",
      "\n",
      "Validation accuracy: 0.517799973487854\n",
      "Epoch 25, CIFAR-10 Batch 1:  \n",
      "Loss: 1.2455830574035645 accuracy: 0.573019802570343\n",
      "\n",
      "Validation accuracy: 0.5181999802589417\n",
      "Epoch 26, CIFAR-10 Batch 1:  \n",
      "Loss: 1.2361104488372803 accuracy: 0.5705445408821106\n",
      "\n",
      "Validation accuracy: 0.5170000195503235\n",
      "Epoch 27, CIFAR-10 Batch 1:  \n",
      "Loss: 1.2186393737792969 accuracy: 0.5792078971862793\n",
      "\n",
      "Validation accuracy: 0.522599995136261\n",
      "Epoch 28, CIFAR-10 Batch 1:  \n",
      "Loss: 1.2019519805908203 accuracy: 0.5816831588745117\n",
      "\n",
      "Validation accuracy: 0.5321999788284302\n",
      "Epoch 29, CIFAR-10 Batch 1:  \n",
      "Loss: 1.1794437170028687 accuracy: 0.5853960514068604\n",
      "\n",
      "Validation accuracy: 0.5361999869346619\n",
      "Epoch 30, CIFAR-10 Batch 1:  \n",
      "Loss: 1.1689708232879639 accuracy: 0.5965346693992615\n",
      "\n",
      "Validation accuracy: 0.5356000065803528\n",
      "Epoch 31, CIFAR-10 Batch 1:  \n",
      "Loss: 1.1644483804702759 accuracy: 0.5928217768669128\n",
      "\n",
      "Validation accuracy: 0.5315999984741211\n",
      "Epoch 32, CIFAR-10 Batch 1:  \n",
      "Loss: 1.1598925590515137 accuracy: 0.6002475023269653\n",
      "\n",
      "Validation accuracy: 0.5297999978065491\n",
      "Epoch 33, CIFAR-10 Batch 1:  \n",
      "Loss: 1.1378610134124756 accuracy: 0.5965346693992615\n",
      "\n",
      "Validation accuracy: 0.5357999801635742\n",
      "Epoch 34, CIFAR-10 Batch 1:  \n",
      "Loss: 1.1243168115615845 accuracy: 0.6014851331710815\n",
      "\n",
      "Validation accuracy: 0.5424000024795532\n",
      "Epoch 35, CIFAR-10 Batch 1:  \n",
      "Loss: 1.100991129875183 accuracy: 0.6150990128517151\n",
      "\n",
      "Validation accuracy: 0.548799991607666\n",
      "Epoch 36, CIFAR-10 Batch 1:  \n",
      "Loss: 1.0887588262557983 accuracy: 0.6212871074676514\n",
      "\n",
      "Validation accuracy: 0.5497999787330627\n",
      "Epoch 37, CIFAR-10 Batch 1:  \n",
      "Loss: 1.0770236253738403 accuracy: 0.6188119053840637\n",
      "\n",
      "Validation accuracy: 0.5540000200271606\n",
      "Epoch 38, CIFAR-10 Batch 1:  \n",
      "Loss: 1.0765724182128906 accuracy: 0.6212871074676514\n",
      "\n",
      "Validation accuracy: 0.550000011920929\n",
      "Epoch 39, CIFAR-10 Batch 1:  \n",
      "Loss: 1.0653387308120728 accuracy: 0.6237623691558838\n",
      "\n",
      "Validation accuracy: 0.550000011920929\n",
      "Epoch 40, CIFAR-10 Batch 1:  \n",
      "Loss: 1.0486515760421753 accuracy: 0.6299505233764648\n",
      "\n",
      "Validation accuracy: 0.553600013256073\n",
      "Epoch 41, CIFAR-10 Batch 1:  \n",
      "Loss: 1.0340168476104736 accuracy: 0.6398515105247498\n",
      "\n",
      "Validation accuracy: 0.5586000084877014\n",
      "Epoch 42, CIFAR-10 Batch 1:  \n",
      "Loss: 1.0168344974517822 accuracy: 0.6547029614448547\n",
      "\n",
      "Validation accuracy: 0.5577999949455261\n",
      "Epoch 43, CIFAR-10 Batch 1:  \n",
      "Loss: 1.017341136932373 accuracy: 0.6336633563041687\n",
      "\n",
      "Validation accuracy: 0.5591999888420105\n",
      "Epoch 44, CIFAR-10 Batch 1:  \n",
      "Loss: 0.9906941652297974 accuracy: 0.6584158539772034\n",
      "\n",
      "Validation accuracy: 0.5662000179290771\n",
      "Epoch 45, CIFAR-10 Batch 1:  \n",
      "Loss: 0.9737443327903748 accuracy: 0.6596534848213196\n",
      "\n",
      "Validation accuracy: 0.571399986743927\n",
      "Epoch 46, CIFAR-10 Batch 1:  \n",
      "Loss: 0.966574490070343 accuracy: 0.6658415794372559\n",
      "\n",
      "Validation accuracy: 0.5705999732017517\n",
      "Epoch 47, CIFAR-10 Batch 1:  \n",
      "Loss: 0.9540196657180786 accuracy: 0.6608911156654358\n",
      "\n",
      "Validation accuracy: 0.5709999799728394\n",
      "Epoch 48, CIFAR-10 Batch 1:  \n",
      "Loss: 0.951545774936676 accuracy: 0.6658415794372559\n",
      "\n",
      "Validation accuracy: 0.5669999718666077\n",
      "Epoch 49, CIFAR-10 Batch 1:  \n",
      "Loss: 0.9501133561134338 accuracy: 0.6608911156654358\n",
      "\n",
      "Validation accuracy: 0.5659999847412109\n",
      "Epoch 50, CIFAR-10 Batch 1:  \n",
      "Loss: 0.9281585812568665 accuracy: 0.6893564462661743\n",
      "\n",
      "Validation accuracy: 0.573199987411499\n",
      "Epoch 51, CIFAR-10 Batch 1:  \n",
      "Loss: 0.9337375164031982 accuracy: 0.6670792102813721\n",
      "\n",
      "Validation accuracy: 0.5691999793052673\n",
      "Epoch 52, CIFAR-10 Batch 1:  \n",
      "Loss: 0.8991262316703796 accuracy: 0.6930692791938782\n",
      "\n",
      "Validation accuracy: 0.5789999961853027\n",
      "Epoch 53, CIFAR-10 Batch 1:  \n",
      "Loss: 0.9005873799324036 accuracy: 0.6930692791938782\n",
      "\n",
      "Validation accuracy: 0.5776000022888184\n",
      "Epoch 54, CIFAR-10 Batch 1:  \n",
      "Loss: 0.8952494859695435 accuracy: 0.6893564462661743\n",
      "\n",
      "Validation accuracy: 0.574999988079071\n",
      "Epoch 55, CIFAR-10 Batch 1:  \n",
      "Loss: 0.8931014537811279 accuracy: 0.6930692791938782\n",
      "\n",
      "Validation accuracy: 0.5735999941825867\n",
      "Epoch 56, CIFAR-10 Batch 1:  \n",
      "Loss: 0.8811695575714111 accuracy: 0.6881188154220581\n",
      "\n",
      "Validation accuracy: 0.5799999833106995\n",
      "Epoch 57, CIFAR-10 Batch 1:  \n",
      "Loss: 0.896809995174408 accuracy: 0.6831682920455933\n",
      "\n",
      "Validation accuracy: 0.5659999847412109\n",
      "Epoch 58, CIFAR-10 Batch 1:  \n",
      "Loss: 0.8862237334251404 accuracy: 0.6905940771102905\n",
      "\n",
      "Validation accuracy: 0.5685999989509583\n",
      "Epoch 59, CIFAR-10 Batch 1:  \n",
      "Loss: 0.837515652179718 accuracy: 0.7029703259468079\n",
      "\n",
      "Validation accuracy: 0.5870000123977661\n",
      "Epoch 60, CIFAR-10 Batch 1:  \n",
      "Loss: 0.8246468901634216 accuracy: 0.728960394859314\n",
      "\n",
      "Validation accuracy: 0.5852000117301941\n",
      "Epoch 61, CIFAR-10 Batch 1:  \n",
      "Loss: 0.84952312707901 accuracy: 0.7004950642585754\n",
      "\n",
      "Validation accuracy: 0.5654000043869019\n",
      "Epoch 62, CIFAR-10 Batch 1:  \n",
      "Loss: 0.8291293382644653 accuracy: 0.7202970385551453\n",
      "\n",
      "Validation accuracy: 0.5734000205993652\n",
      "Epoch 63, CIFAR-10 Batch 1:  \n",
      "Loss: 0.826054036617279 accuracy: 0.7165841460227966\n",
      "\n",
      "Validation accuracy: 0.5803999900817871\n",
      "Epoch 64, CIFAR-10 Batch 1:  \n",
      "Loss: 0.8038647174835205 accuracy: 0.7202970385551453\n",
      "\n",
      "Validation accuracy: 0.5848000049591064\n",
      "Epoch 65, CIFAR-10 Batch 1:  \n",
      "Loss: 0.7990358471870422 accuracy: 0.7301980257034302\n",
      "\n",
      "Validation accuracy: 0.5809999704360962\n",
      "Epoch 66, CIFAR-10 Batch 1:  \n",
      "Loss: 0.7953974604606628 accuracy: 0.7301980257034302\n",
      "\n",
      "Validation accuracy: 0.5831999778747559\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67, CIFAR-10 Batch 1:  \n",
      "Loss: 0.7700469493865967 accuracy: 0.7376237511634827\n",
      "\n",
      "Validation accuracy: 0.5888000130653381\n",
      "Epoch 68, CIFAR-10 Batch 1:  \n",
      "Loss: 0.7640321850776672 accuracy: 0.7462871074676514\n",
      "\n",
      "Validation accuracy: 0.5845999717712402\n",
      "Epoch 69, CIFAR-10 Batch 1:  \n",
      "Loss: 0.7517954707145691 accuracy: 0.7537128925323486\n",
      "\n",
      "Validation accuracy: 0.5856000185012817\n",
      "Epoch 70, CIFAR-10 Batch 1:  \n",
      "Loss: 0.7618221044540405 accuracy: 0.7413366436958313\n",
      "\n",
      "Validation accuracy: 0.5863999724388123\n",
      "Epoch 71, CIFAR-10 Batch 1:  \n",
      "Loss: 0.7441316246986389 accuracy: 0.7512376308441162\n",
      "\n",
      "Validation accuracy: 0.5838000178337097\n",
      "Epoch 72, CIFAR-10 Batch 1:  \n",
      "Loss: 0.7404768466949463 accuracy: 0.7537128925323486\n",
      "\n",
      "Validation accuracy: 0.5853999853134155\n",
      "Epoch 73, CIFAR-10 Batch 1:  \n",
      "Loss: 0.70847088098526 accuracy: 0.7537128925323486\n",
      "\n",
      "Validation accuracy: 0.5929999947547913\n",
      "Epoch 74, CIFAR-10 Batch 1:  \n",
      "Loss: 0.7484772801399231 accuracy: 0.7512376308441162\n",
      "\n",
      "Validation accuracy: 0.5807999968528748\n",
      "Epoch 75, CIFAR-10 Batch 1:  \n",
      "Loss: 0.7124704718589783 accuracy: 0.7623762488365173\n",
      "\n",
      "Validation accuracy: 0.5856000185012817\n",
      "Epoch 76, CIFAR-10 Batch 1:  \n",
      "Loss: 0.6843019127845764 accuracy: 0.7698019742965698\n",
      "\n",
      "Validation accuracy: 0.5929999947547913\n",
      "Epoch 77, CIFAR-10 Batch 1:  \n",
      "Loss: 0.6776625514030457 accuracy: 0.7759901285171509\n",
      "\n",
      "Validation accuracy: 0.592199981212616\n",
      "Epoch 78, CIFAR-10 Batch 1:  \n",
      "Loss: 0.7106145620346069 accuracy: 0.7623762488365173\n",
      "\n",
      "Validation accuracy: 0.5878000259399414\n",
      "Epoch 79, CIFAR-10 Batch 1:  \n",
      "Loss: 0.6635448336601257 accuracy: 0.7834158539772034\n",
      "\n",
      "Validation accuracy: 0.5928000211715698\n",
      "Epoch 80, CIFAR-10 Batch 1:  \n",
      "Loss: 0.6774033904075623 accuracy: 0.7722772359848022\n",
      "\n",
      "Validation accuracy: 0.5914000272750854\n",
      "Epoch 81, CIFAR-10 Batch 1:  \n",
      "Loss: 0.6916443705558777 accuracy: 0.7747524976730347\n",
      "\n",
      "Validation accuracy: 0.5838000178337097\n",
      "Epoch 82, CIFAR-10 Batch 1:  \n",
      "Loss: 0.6818099617958069 accuracy: 0.7759901285171509\n",
      "\n",
      "Validation accuracy: 0.5881999731063843\n",
      "Epoch 83, CIFAR-10 Batch 1:  \n",
      "Loss: 0.6410627365112305 accuracy: 0.7896039485931396\n",
      "\n",
      "Validation accuracy: 0.5971999764442444\n",
      "Epoch 84, CIFAR-10 Batch 1:  \n",
      "Loss: 0.6356028318405151 accuracy: 0.8007425665855408\n",
      "\n",
      "Validation accuracy: 0.5974000096321106\n",
      "Epoch 85, CIFAR-10 Batch 1:  \n",
      "Loss: 0.641105592250824 accuracy: 0.7896039485931396\n",
      "\n",
      "Validation accuracy: 0.5938000082969666\n",
      "Epoch 86, CIFAR-10 Batch 1:  \n",
      "Loss: 0.6561722755432129 accuracy: 0.7797029614448547\n",
      "\n",
      "Validation accuracy: 0.5838000178337097\n",
      "Epoch 87, CIFAR-10 Batch 1:  \n",
      "Loss: 0.6237353682518005 accuracy: 0.7995049357414246\n",
      "\n",
      "Validation accuracy: 0.597599983215332\n",
      "Epoch 88, CIFAR-10 Batch 1:  \n",
      "Loss: 0.6061327457427979 accuracy: 0.801980197429657\n",
      "\n",
      "Validation accuracy: 0.5961999893188477\n",
      "Epoch 89, CIFAR-10 Batch 1:  \n",
      "Loss: 0.5892974734306335 accuracy: 0.8118811845779419\n",
      "\n",
      "Validation accuracy: 0.6019999980926514\n",
      "Epoch 90, CIFAR-10 Batch 1:  \n",
      "Loss: 0.5883370041847229 accuracy: 0.8118811845779419\n",
      "\n",
      "Validation accuracy: 0.5983999967575073\n",
      "Epoch 91, CIFAR-10 Batch 1:  \n",
      "Loss: 0.601611852645874 accuracy: 0.8081682920455933\n",
      "\n",
      "Validation accuracy: 0.6000000238418579\n",
      "Epoch 92, CIFAR-10 Batch 1:  \n",
      "Loss: 0.6005433797836304 accuracy: 0.8081682920455933\n",
      "\n",
      "Validation accuracy: 0.5932000279426575\n",
      "Epoch 93, CIFAR-10 Batch 1:  \n",
      "Loss: 0.5825135111808777 accuracy: 0.8217821717262268\n",
      "\n",
      "Validation accuracy: 0.59579998254776\n",
      "Epoch 94, CIFAR-10 Batch 1:  \n",
      "Loss: 0.6315222978591919 accuracy: 0.7896039485931396\n",
      "\n",
      "Validation accuracy: 0.58160001039505\n",
      "Epoch 95, CIFAR-10 Batch 1:  \n",
      "Loss: 0.5668458938598633 accuracy: 0.823019802570343\n",
      "\n",
      "Validation accuracy: 0.6050000190734863\n",
      "Epoch 96, CIFAR-10 Batch 1:  \n",
      "Loss: 0.5501348376274109 accuracy: 0.8143564462661743\n",
      "\n",
      "Validation accuracy: 0.6050000190734863\n",
      "Epoch 97, CIFAR-10 Batch 1:  \n",
      "Loss: 0.5389026999473572 accuracy: 0.8267326951026917\n",
      "\n",
      "Validation accuracy: 0.603600025177002\n",
      "Epoch 98, CIFAR-10 Batch 1:  \n",
      "Loss: 0.5303239226341248 accuracy: 0.8267326951026917\n",
      "\n",
      "Validation accuracy: 0.605400025844574\n",
      "Epoch 99, CIFAR-10 Batch 1:  \n",
      "Loss: 0.5332183837890625 accuracy: 0.8254950642585754\n",
      "\n",
      "Validation accuracy: 0.6037999987602234\n",
      "Epoch 100, CIFAR-10 Batch 1:  \n",
      "Loss: 0.5187967419624329 accuracy: 0.8242574334144592\n",
      "\n",
      "Validation accuracy: 0.6083999872207642\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "print('Checking the Training on a Single Batch...')\n",
    "loss_data = []\n",
    "acc_data = []\n",
    "val_acc_data = []\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        batch_i = 1\n",
    "        for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "            train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "        print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "        loss, acc, val_acc = print_stats(sess, batch_features, batch_labels, cost, accuracy)\n",
    "        loss_data.append(loss)\n",
    "        acc_data.append(acc)\n",
    "        val_acc_data.append(val_acc)\n",
    "     \n",
    "    # Show a plot of accuracy over epochs      \n",
    "    def plot_accuracy(\n",
    "        title,\n",
    "        accuracy,\n",
    "        val_accuracy,\n",
    "        plot_n_batches=100):\n",
    "        \"\"\"\n",
    "        Plot loss and print stats of weights using an example neural network\n",
    "        \"\"\"\n",
    "        colors = ['r', 'b', 'g', 'c', 'y', 'k']\n",
    "        label_accs = []\n",
    "        label_loss = []\n",
    "\n",
    "        plt.plot(accuracy, colors[0], label=\"training_accuracy\")\n",
    "        plt.plot(val_accuracy, colors[1], label=\"validation_accuracy\")\n",
    "        plt.title(title)\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABDQAAAIqCAYAAADb4hqrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nHzlLw9kfYqZmAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x22ae15020b8>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 277,
       "width": 538
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_accuracy(\"Accuracy\", acc_data, val_acc_data, epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully Train the Model\n",
    "Now that you got a good accuracy with a single CIFAR-10 batch, try it with all five batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch  1, CIFAR-10 Batch 1:  \n",
      "Loss: 2.247932195663452 accuracy: 0.17450495064258575\n",
      "\n",
      "Validation accuracy: 0.14880000054836273\n",
      "Epoch  1, CIFAR-10 Batch 2:  \n",
      "Loss: 2.145843744277954 accuracy: 0.2611386179924011\n",
      "\n",
      "Validation accuracy: 0.2572000026702881\n",
      "Epoch  1, CIFAR-10 Batch 3:  \n",
      "Loss: 1.9652472734451294 accuracy: 0.2970297038555145\n",
      "\n",
      "Validation accuracy: 0.28700000047683716\n",
      "Epoch  1, CIFAR-10 Batch 4:  \n",
      "Loss: 1.883435845375061 accuracy: 0.3378712832927704\n",
      "\n",
      "Validation accuracy: 0.3192000091075897\n",
      "Epoch  1, CIFAR-10 Batch 5:  \n",
      "Loss: 1.8147786855697632 accuracy: 0.35148516297340393\n",
      "\n",
      "Validation accuracy: 0.3610000014305115\n",
      "Epoch  2, CIFAR-10 Batch 1:  \n",
      "Loss: 1.773059368133545 accuracy: 0.38737624883651733\n",
      "\n",
      "Validation accuracy: 0.3783999979496002\n",
      "Epoch  2, CIFAR-10 Batch 2:  \n",
      "Loss: 1.7369855642318726 accuracy: 0.38985148072242737\n",
      "\n",
      "Validation accuracy: 0.39719998836517334\n",
      "Epoch  2, CIFAR-10 Batch 3:  \n",
      "Loss: 1.6317247152328491 accuracy: 0.43440595269203186\n",
      "\n",
      "Validation accuracy: 0.39820000529289246\n",
      "Epoch  2, CIFAR-10 Batch 4:  \n",
      "Loss: 1.617597222328186 accuracy: 0.42574256658554077\n",
      "\n",
      "Validation accuracy: 0.40400001406669617\n",
      "Epoch  2, CIFAR-10 Batch 5:  \n",
      "Loss: 1.5940970182418823 accuracy: 0.426980197429657\n",
      "\n",
      "Validation accuracy: 0.4253999888896942\n",
      "Epoch  3, CIFAR-10 Batch 1:  \n",
      "Loss: 1.5733546018600464 accuracy: 0.4653465449810028\n",
      "\n",
      "Validation accuracy: 0.4375999867916107\n",
      "Epoch  3, CIFAR-10 Batch 2:  \n",
      "Loss: 1.575083613395691 accuracy: 0.43316832184791565\n",
      "\n",
      "Validation accuracy: 0.43380001187324524\n",
      "Epoch  3, CIFAR-10 Batch 3:  \n",
      "Loss: 1.4970712661743164 accuracy: 0.48638615012168884\n",
      "\n",
      "Validation accuracy: 0.4426000118255615\n",
      "Epoch  3, CIFAR-10 Batch 4:  \n",
      "Loss: 1.4699729681015015 accuracy: 0.46658414602279663\n",
      "\n",
      "Validation accuracy: 0.45719999074935913\n",
      "Epoch  3, CIFAR-10 Batch 5:  \n",
      "Loss: 1.4503991603851318 accuracy: 0.4826732575893402\n",
      "\n",
      "Validation accuracy: 0.4650000035762787\n",
      "Epoch  4, CIFAR-10 Batch 1:  \n",
      "Loss: 1.4756741523742676 accuracy: 0.4752475321292877\n",
      "\n",
      "Validation accuracy: 0.4657999873161316\n",
      "Epoch  4, CIFAR-10 Batch 2:  \n",
      "Loss: 1.4444137811660767 accuracy: 0.4888613820075989\n",
      "\n",
      "Validation accuracy: 0.46560001373291016\n",
      "Epoch  4, CIFAR-10 Batch 3:  \n",
      "Loss: 1.3935680389404297 accuracy: 0.5222772359848022\n",
      "\n",
      "Validation accuracy: 0.4814000129699707\n",
      "Epoch  4, CIFAR-10 Batch 4:  \n",
      "Loss: 1.3995915651321411 accuracy: 0.49628713726997375\n",
      "\n",
      "Validation accuracy: 0.475600004196167\n",
      "Epoch  4, CIFAR-10 Batch 5:  \n",
      "Loss: 1.3873279094696045 accuracy: 0.5123762488365173\n",
      "\n",
      "Validation accuracy: 0.47999998927116394\n",
      "Epoch  5, CIFAR-10 Batch 1:  \n",
      "Loss: 1.387982964515686 accuracy: 0.49628713726997375\n",
      "\n",
      "Validation accuracy: 0.490200012922287\n",
      "Epoch  5, CIFAR-10 Batch 2:  \n",
      "Loss: 1.3695298433303833 accuracy: 0.5160890817642212\n",
      "\n",
      "Validation accuracy: 0.4918000102043152\n",
      "Epoch  5, CIFAR-10 Batch 3:  \n",
      "Loss: 1.3189139366149902 accuracy: 0.530940592288971\n",
      "\n",
      "Validation accuracy: 0.5001999735832214\n",
      "Epoch  5, CIFAR-10 Batch 4:  \n",
      "Loss: 1.3387788534164429 accuracy: 0.5457921028137207\n",
      "\n",
      "Validation accuracy: 0.5034000277519226\n",
      "Epoch  5, CIFAR-10 Batch 5:  \n",
      "Loss: 1.3459335565567017 accuracy: 0.5371286869049072\n",
      "\n",
      "Validation accuracy: 0.503600001335144\n",
      "Epoch  6, CIFAR-10 Batch 1:  \n",
      "Loss: 1.3404284715652466 accuracy: 0.5247524976730347\n",
      "\n",
      "Validation accuracy: 0.5041999816894531\n",
      "Epoch  6, CIFAR-10 Batch 2:  \n",
      "Loss: 1.348981499671936 accuracy: 0.5321782231330872\n",
      "\n",
      "Validation accuracy: 0.4952000081539154\n",
      "Epoch  6, CIFAR-10 Batch 3:  \n",
      "Loss: 1.2861831188201904 accuracy: 0.5594059228897095\n",
      "\n",
      "Validation accuracy: 0.5157999992370605\n",
      "Epoch  6, CIFAR-10 Batch 4:  \n",
      "Loss: 1.310666561126709 accuracy: 0.5420792102813721\n",
      "\n",
      "Validation accuracy: 0.5157999992370605\n",
      "Epoch  6, CIFAR-10 Batch 5:  \n",
      "Loss: 1.2894247770309448 accuracy: 0.5495049357414246\n",
      "\n",
      "Validation accuracy: 0.5285999774932861\n",
      "Epoch  7, CIFAR-10 Batch 1:  \n",
      "Loss: 1.2863476276397705 accuracy: 0.5396039485931396\n",
      "\n",
      "Validation accuracy: 0.5192000269889832\n",
      "Epoch  7, CIFAR-10 Batch 2:  \n",
      "Loss: 1.2801978588104248 accuracy: 0.5655940771102905\n",
      "\n",
      "Validation accuracy: 0.5296000242233276\n",
      "Epoch  7, CIFAR-10 Batch 3:  \n",
      "Loss: 1.2361736297607422 accuracy: 0.5556930899620056\n",
      "\n",
      "Validation accuracy: 0.5260000228881836\n",
      "Epoch  7, CIFAR-10 Batch 4:  \n",
      "Loss: 1.271444320678711 accuracy: 0.5594059228897095\n",
      "\n",
      "Validation accuracy: 0.52920001745224\n",
      "Epoch  7, CIFAR-10 Batch 5:  \n",
      "Loss: 1.2501132488250732 accuracy: 0.5705445408821106\n",
      "\n",
      "Validation accuracy: 0.5382000207901001\n",
      "Epoch  8, CIFAR-10 Batch 1:  \n",
      "Loss: 1.251916766166687 accuracy: 0.5581682920455933\n",
      "\n",
      "Validation accuracy: 0.531000018119812\n",
      "Epoch  8, CIFAR-10 Batch 2:  \n",
      "Loss: 1.245410680770874 accuracy: 0.5618811845779419\n",
      "\n",
      "Validation accuracy: 0.5422000288963318\n",
      "Epoch  8, CIFAR-10 Batch 3:  \n",
      "Loss: 1.1957095861434937 accuracy: 0.5742574334144592\n",
      "\n",
      "Validation accuracy: 0.5386000275611877\n",
      "Epoch  8, CIFAR-10 Batch 4:  \n",
      "Loss: 1.2243058681488037 accuracy: 0.5816831588745117\n",
      "\n",
      "Validation accuracy: 0.5460000038146973\n",
      "Epoch  8, CIFAR-10 Batch 5:  \n",
      "Loss: 1.2108066082000732 accuracy: 0.5829207897186279\n",
      "\n",
      "Validation accuracy: 0.5483999848365784\n",
      "Epoch  9, CIFAR-10 Batch 1:  \n",
      "Loss: 1.217020034790039 accuracy: 0.5680692791938782\n",
      "\n",
      "Validation accuracy: 0.546999990940094\n",
      "Epoch  9, CIFAR-10 Batch 2:  \n",
      "Loss: 1.2077045440673828 accuracy: 0.5668317079544067\n",
      "\n",
      "Validation accuracy: 0.5490000247955322\n",
      "Epoch  9, CIFAR-10 Batch 3:  \n",
      "Loss: 1.1584116220474243 accuracy: 0.5928217768669128\n",
      "\n",
      "Validation accuracy: 0.5526000261306763\n",
      "Epoch  9, CIFAR-10 Batch 4:  \n",
      "Loss: 1.190759301185608 accuracy: 0.594059407711029\n",
      "\n",
      "Validation accuracy: 0.5622000098228455\n",
      "Epoch  9, CIFAR-10 Batch 5:  \n",
      "Loss: 1.1762834787368774 accuracy: 0.5891088843345642\n",
      "\n",
      "Validation accuracy: 0.5631999969482422\n",
      "Epoch 10, CIFAR-10 Batch 1:  \n",
      "Loss: 1.1821895837783813 accuracy: 0.5754950642585754\n",
      "\n",
      "Validation accuracy: 0.555400013923645\n",
      "Epoch 10, CIFAR-10 Batch 2:  \n",
      "Loss: 1.1692780256271362 accuracy: 0.6027227640151978\n",
      "\n",
      "Validation accuracy: 0.5601999759674072\n",
      "Epoch 10, CIFAR-10 Batch 3:  \n",
      "Loss: 1.1240695714950562 accuracy: 0.6126237511634827\n",
      "\n",
      "Validation accuracy: 0.5600000023841858\n",
      "Epoch 10, CIFAR-10 Batch 4:  \n",
      "Loss: 1.1606190204620361 accuracy: 0.594059407711029\n",
      "\n",
      "Validation accuracy: 0.5734000205993652\n",
      "Epoch 10, CIFAR-10 Batch 5:  \n",
      "Loss: 1.1453676223754883 accuracy: 0.6064356565475464\n",
      "\n",
      "Validation accuracy: 0.5702000260353088\n",
      "Epoch 11, CIFAR-10 Batch 1:  \n",
      "Loss: 1.155144214630127 accuracy: 0.5952970385551453\n",
      "\n",
      "Validation accuracy: 0.5655999779701233\n",
      "Epoch 11, CIFAR-10 Batch 2:  \n",
      "Loss: 1.1417477130889893 accuracy: 0.6014851331710815\n",
      "\n",
      "Validation accuracy: 0.5687999725341797\n",
      "Epoch 11, CIFAR-10 Batch 3:  \n",
      "Loss: 1.1083855628967285 accuracy: 0.6237623691558838\n",
      "\n",
      "Validation accuracy: 0.5649999976158142\n",
      "Epoch 11, CIFAR-10 Batch 4:  \n",
      "Loss: 1.132004737854004 accuracy: 0.6200494766235352\n",
      "\n",
      "Validation accuracy: 0.5803999900817871\n",
      "Epoch 11, CIFAR-10 Batch 5:  \n",
      "Loss: 1.1262776851654053 accuracy: 0.603960394859314\n",
      "\n",
      "Validation accuracy: 0.5781999826431274\n",
      "Epoch 12, CIFAR-10 Batch 1:  \n",
      "Loss: 1.1366411447525024 accuracy: 0.5928217768669128\n",
      "\n",
      "Validation accuracy: 0.5734000205993652\n",
      "Epoch 12, CIFAR-10 Batch 2:  \n",
      "Loss: 1.1298702955245972 accuracy: 0.6113861203193665\n",
      "\n",
      "Validation accuracy: 0.5658000111579895\n",
      "Epoch 12, CIFAR-10 Batch 3:  \n",
      "Loss: 1.0783661603927612 accuracy: 0.6349009871482849\n",
      "\n",
      "Validation accuracy: 0.5795999765396118\n",
      "Epoch 12, CIFAR-10 Batch 4:  \n",
      "Loss: 1.1101244688034058 accuracy: 0.6262376308441162\n",
      "\n",
      "Validation accuracy: 0.5839999914169312\n",
      "Epoch 12, CIFAR-10 Batch 5:  \n",
      "Loss: 1.096545696258545 accuracy: 0.6225247383117676\n",
      "\n",
      "Validation accuracy: 0.5932000279426575\n",
      "Epoch 13, CIFAR-10 Batch 1:  \n",
      "Loss: 1.1019283533096313 accuracy: 0.6051980257034302\n",
      "\n",
      "Validation accuracy: 0.5845999717712402\n",
      "Epoch 13, CIFAR-10 Batch 2:  \n",
      "Loss: 1.0916531085968018 accuracy: 0.6237623691558838\n",
      "\n",
      "Validation accuracy: 0.5802000164985657\n",
      "Epoch 13, CIFAR-10 Batch 3:  \n",
      "Loss: 1.0426619052886963 accuracy: 0.6398515105247498\n",
      "\n",
      "Validation accuracy: 0.5935999751091003\n",
      "Epoch 13, CIFAR-10 Batch 4:  \n",
      "Loss: 1.1031461954116821 accuracy: 0.6175742745399475\n",
      "\n",
      "Validation accuracy: 0.5799999833106995\n",
      "Epoch 13, CIFAR-10 Batch 5:  \n",
      "Loss: 1.068405032157898 accuracy: 0.6373762488365173\n",
      "\n",
      "Validation accuracy: 0.6000000238418579\n",
      "Epoch 14, CIFAR-10 Batch 1:  \n",
      "Loss: 1.0840977430343628 accuracy: 0.6188119053840637\n",
      "\n",
      "Validation accuracy: 0.5870000123977661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, CIFAR-10 Batch 2:  \n",
      "Loss: 1.0751194953918457 accuracy: 0.625\n",
      "\n",
      "Validation accuracy: 0.5834000110626221\n",
      "Epoch 14, CIFAR-10 Batch 3:  \n",
      "Loss: 1.0176184177398682 accuracy: 0.6398515105247498\n",
      "\n",
      "Validation accuracy: 0.5985999703407288\n",
      "Epoch 14, CIFAR-10 Batch 4:  \n",
      "Loss: 1.06186044216156 accuracy: 0.6324257254600525\n",
      "\n",
      "Validation accuracy: 0.598800003528595\n",
      "Epoch 14, CIFAR-10 Batch 5:  \n",
      "Loss: 1.0428390502929688 accuracy: 0.6410890817642212\n",
      "\n",
      "Validation accuracy: 0.600600004196167\n",
      "Epoch 15, CIFAR-10 Batch 1:  \n",
      "Loss: 1.0653162002563477 accuracy: 0.625\n",
      "\n",
      "Validation accuracy: 0.5978000164031982\n",
      "Epoch 15, CIFAR-10 Batch 2:  \n",
      "Loss: 1.0464324951171875 accuracy: 0.646039605140686\n",
      "\n",
      "Validation accuracy: 0.6007999777793884\n",
      "Epoch 15, CIFAR-10 Batch 3:  \n",
      "Loss: 1.0151431560516357 accuracy: 0.6336633563041687\n",
      "\n",
      "Validation accuracy: 0.5950000286102295\n",
      "Epoch 15, CIFAR-10 Batch 4:  \n",
      "Loss: 1.0439238548278809 accuracy: 0.6386138796806335\n",
      "\n",
      "Validation accuracy: 0.6057999730110168\n",
      "Epoch 15, CIFAR-10 Batch 5:  \n",
      "Loss: 1.0243582725524902 accuracy: 0.6509901285171509\n",
      "\n",
      "Validation accuracy: 0.6079999804496765\n",
      "Epoch 16, CIFAR-10 Batch 1:  \n",
      "Loss: 1.0441176891326904 accuracy: 0.6485148668289185\n",
      "\n",
      "Validation accuracy: 0.6064000129699707\n",
      "Epoch 16, CIFAR-10 Batch 2:  \n",
      "Loss: 1.031187891960144 accuracy: 0.6410890817642212\n",
      "\n",
      "Validation accuracy: 0.6015999913215637\n",
      "Epoch 16, CIFAR-10 Batch 3:  \n",
      "Loss: 1.0048389434814453 accuracy: 0.6373762488365173\n",
      "\n",
      "Validation accuracy: 0.6019999980926514\n",
      "Epoch 16, CIFAR-10 Batch 4:  \n",
      "Loss: 1.0433692932128906 accuracy: 0.6299505233764648\n",
      "\n",
      "Validation accuracy: 0.5983999967575073\n",
      "Epoch 16, CIFAR-10 Batch 5:  \n",
      "Loss: 1.0085643529891968 accuracy: 0.6658415794372559\n",
      "\n",
      "Validation accuracy: 0.6096000075340271\n",
      "Epoch 17, CIFAR-10 Batch 1:  \n",
      "Loss: 1.0160948038101196 accuracy: 0.6608911156654358\n",
      "\n",
      "Validation accuracy: 0.6079999804496765\n",
      "Epoch 17, CIFAR-10 Batch 2:  \n",
      "Loss: 1.009705901145935 accuracy: 0.6534653306007385\n",
      "\n",
      "Validation accuracy: 0.6078000068664551\n",
      "Epoch 17, CIFAR-10 Batch 3:  \n",
      "Loss: 0.981331467628479 accuracy: 0.6522276997566223\n",
      "\n",
      "Validation accuracy: 0.6065999865531921\n",
      "Epoch 17, CIFAR-10 Batch 4:  \n",
      "Loss: 1.0164071321487427 accuracy: 0.6448019742965698\n",
      "\n",
      "Validation accuracy: 0.6078000068664551\n",
      "Epoch 17, CIFAR-10 Batch 5:  \n",
      "Loss: 0.987480103969574 accuracy: 0.6819307208061218\n",
      "\n",
      "Validation accuracy: 0.6158000230789185\n",
      "Epoch 18, CIFAR-10 Batch 1:  \n",
      "Loss: 1.0184699296951294 accuracy: 0.646039605140686\n",
      "\n",
      "Validation accuracy: 0.6086000204086304\n",
      "Epoch 18, CIFAR-10 Batch 2:  \n",
      "Loss: 0.9928053021430969 accuracy: 0.6547029614448547\n",
      "\n",
      "Validation accuracy: 0.6182000041007996\n",
      "Epoch 18, CIFAR-10 Batch 3:  \n",
      "Loss: 0.9623130559921265 accuracy: 0.6547029614448547\n",
      "\n",
      "Validation accuracy: 0.6132000088691711\n",
      "Epoch 18, CIFAR-10 Batch 4:  \n",
      "Loss: 0.9878547787666321 accuracy: 0.6596534848213196\n",
      "\n",
      "Validation accuracy: 0.6209999918937683\n",
      "Epoch 18, CIFAR-10 Batch 5:  \n",
      "Loss: 0.9720221161842346 accuracy: 0.6732673048973083\n",
      "\n",
      "Validation accuracy: 0.6173999905586243\n",
      "Epoch 19, CIFAR-10 Batch 1:  \n",
      "Loss: 0.981286883354187 accuracy: 0.6782178282737732\n",
      "\n",
      "Validation accuracy: 0.6241999864578247\n",
      "Epoch 19, CIFAR-10 Batch 2:  \n",
      "Loss: 0.9688892960548401 accuracy: 0.6658415794372559\n",
      "\n",
      "Validation accuracy: 0.6223999857902527\n",
      "Epoch 19, CIFAR-10 Batch 3:  \n",
      "Loss: 0.9301362037658691 accuracy: 0.6695544719696045\n",
      "\n",
      "Validation accuracy: 0.6194000244140625\n",
      "Epoch 19, CIFAR-10 Batch 4:  \n",
      "Loss: 0.9586284160614014 accuracy: 0.6745049357414246\n",
      "\n",
      "Validation accuracy: 0.6277999877929688\n",
      "Epoch 19, CIFAR-10 Batch 5:  \n",
      "Loss: 0.9481980800628662 accuracy: 0.6881188154220581\n",
      "\n",
      "Validation accuracy: 0.6245999932289124\n",
      "Epoch 20, CIFAR-10 Batch 1:  \n",
      "Loss: 0.9647673964500427 accuracy: 0.6831682920455933\n",
      "\n",
      "Validation accuracy: 0.6290000081062317\n",
      "Epoch 20, CIFAR-10 Batch 2:  \n",
      "Loss: 0.9627095460891724 accuracy: 0.6683168411254883\n",
      "\n",
      "Validation accuracy: 0.6295999884605408\n",
      "Epoch 20, CIFAR-10 Batch 3:  \n",
      "Loss: 0.9436830282211304 accuracy: 0.6683168411254883\n",
      "\n",
      "Validation accuracy: 0.6123999953269958\n",
      "Epoch 20, CIFAR-10 Batch 4:  \n",
      "Loss: 0.9654075503349304 accuracy: 0.6707921028137207\n",
      "\n",
      "Validation accuracy: 0.6209999918937683\n",
      "Epoch 20, CIFAR-10 Batch 5:  \n",
      "Loss: 0.939453661441803 accuracy: 0.6881188154220581\n",
      "\n",
      "Validation accuracy: 0.6273999810218811\n",
      "Epoch 21, CIFAR-10 Batch 1:  \n",
      "Loss: 0.9527040719985962 accuracy: 0.6881188154220581\n",
      "\n",
      "Validation accuracy: 0.6295999884605408\n",
      "Epoch 21, CIFAR-10 Batch 2:  \n",
      "Loss: 0.9437885880470276 accuracy: 0.6782178282737732\n",
      "\n",
      "Validation accuracy: 0.628600001335144\n",
      "Epoch 21, CIFAR-10 Batch 3:  \n",
      "Loss: 0.9516055583953857 accuracy: 0.655940592288971\n",
      "\n",
      "Validation accuracy: 0.6111999750137329\n",
      "Epoch 21, CIFAR-10 Batch 4:  \n",
      "Loss: 0.958403468132019 accuracy: 0.6806930899620056\n",
      "\n",
      "Validation accuracy: 0.6258000135421753\n",
      "Epoch 21, CIFAR-10 Batch 5:  \n",
      "Loss: 0.9241604804992676 accuracy: 0.6905940771102905\n",
      "\n",
      "Validation accuracy: 0.628000020980835\n",
      "Epoch 22, CIFAR-10 Batch 1:  \n",
      "Loss: 0.9464991092681885 accuracy: 0.6856435537338257\n",
      "\n",
      "Validation accuracy: 0.6355999708175659\n",
      "Epoch 22, CIFAR-10 Batch 2:  \n",
      "Loss: 0.9417719841003418 accuracy: 0.6856435537338257\n",
      "\n",
      "Validation accuracy: 0.626800000667572\n",
      "Epoch 22, CIFAR-10 Batch 3:  \n",
      "Loss: 0.9145276546478271 accuracy: 0.6856435537338257\n",
      "\n",
      "Validation accuracy: 0.6182000041007996\n",
      "Epoch 22, CIFAR-10 Batch 4:  \n",
      "Loss: 0.9475679397583008 accuracy: 0.6695544719696045\n",
      "\n",
      "Validation accuracy: 0.621999979019165\n",
      "Epoch 22, CIFAR-10 Batch 5:  \n",
      "Loss: 0.9098767638206482 accuracy: 0.7004950642585754\n",
      "\n",
      "Validation accuracy: 0.629800021648407\n",
      "Epoch 23, CIFAR-10 Batch 1:  \n",
      "Loss: 0.9364333748817444 accuracy: 0.6967821717262268\n",
      "\n",
      "Validation accuracy: 0.6353999972343445\n",
      "Epoch 23, CIFAR-10 Batch 2:  \n",
      "Loss: 0.9128494262695312 accuracy: 0.6905940771102905\n",
      "\n",
      "Validation accuracy: 0.6349999904632568\n",
      "Epoch 23, CIFAR-10 Batch 3:  \n",
      "Loss: 0.891068160533905 accuracy: 0.6819307208061218\n",
      "\n",
      "Validation accuracy: 0.621399998664856\n",
      "Epoch 23, CIFAR-10 Batch 4:  \n",
      "Loss: 0.9286606907844543 accuracy: 0.6943069100379944\n",
      "\n",
      "Validation accuracy: 0.6323999762535095\n",
      "Epoch 23, CIFAR-10 Batch 5:  \n",
      "Loss: 0.9025646448135376 accuracy: 0.7079207897186279\n",
      "\n",
      "Validation accuracy: 0.6299999952316284\n",
      "Epoch 24, CIFAR-10 Batch 1:  \n",
      "Loss: 0.9360620975494385 accuracy: 0.6905940771102905\n",
      "\n",
      "Validation accuracy: 0.6291999816894531\n",
      "Epoch 24, CIFAR-10 Batch 2:  \n",
      "Loss: 0.9179607629776001 accuracy: 0.6955445408821106\n",
      "\n",
      "Validation accuracy: 0.6403999924659729\n",
      "Epoch 24, CIFAR-10 Batch 3:  \n",
      "Loss: 0.8847243785858154 accuracy: 0.6794554591178894\n",
      "\n",
      "Validation accuracy: 0.621999979019165\n",
      "Epoch 24, CIFAR-10 Batch 4:  \n",
      "Loss: 0.8929135799407959 accuracy: 0.6918317079544067\n",
      "\n",
      "Validation accuracy: 0.6359999775886536\n",
      "Epoch 24, CIFAR-10 Batch 5:  \n",
      "Loss: 0.8975682258605957 accuracy: 0.7116336822509766\n",
      "\n",
      "Validation accuracy: 0.6313999891281128\n",
      "Epoch 25, CIFAR-10 Batch 1:  \n",
      "Loss: 0.9086484909057617 accuracy: 0.6930692791938782\n",
      "\n",
      "Validation accuracy: 0.6302000284194946\n",
      "Epoch 25, CIFAR-10 Batch 2:  \n",
      "Loss: 0.8813676834106445 accuracy: 0.7042078971862793\n",
      "\n",
      "Validation accuracy: 0.6420000195503235\n",
      "Epoch 25, CIFAR-10 Batch 3:  \n",
      "Loss: 0.8464940786361694 accuracy: 0.7029703259468079\n",
      "\n",
      "Validation accuracy: 0.6380000114440918\n",
      "Epoch 25, CIFAR-10 Batch 4:  \n",
      "Loss: 0.8817105293273926 accuracy: 0.6930692791938782\n",
      "\n",
      "Validation accuracy: 0.6416000127792358\n",
      "Epoch 25, CIFAR-10 Batch 5:  \n",
      "Loss: 0.8680837750434875 accuracy: 0.7277227640151978\n",
      "\n",
      "Validation accuracy: 0.6355999708175659\n",
      "Epoch 26, CIFAR-10 Batch 1:  \n",
      "Loss: 0.8884841799736023 accuracy: 0.7004950642585754\n",
      "\n",
      "Validation accuracy: 0.6384000182151794\n",
      "Epoch 26, CIFAR-10 Batch 2:  \n",
      "Loss: 0.8732168078422546 accuracy: 0.7091584205627441\n",
      "\n",
      "Validation accuracy: 0.6424000263214111\n",
      "Epoch 26, CIFAR-10 Batch 3:  \n",
      "Loss: 0.8591173887252808 accuracy: 0.6819307208061218\n",
      "\n",
      "Validation accuracy: 0.6312000155448914\n",
      "Epoch 26, CIFAR-10 Batch 4:  \n",
      "Loss: 0.8724916577339172 accuracy: 0.698019802570343\n",
      "\n",
      "Validation accuracy: 0.6420000195503235\n",
      "Epoch 26, CIFAR-10 Batch 5:  \n",
      "Loss: 0.8504844903945923 accuracy: 0.7314356565475464\n",
      "\n",
      "Validation accuracy: 0.6435999870300293\n",
      "Epoch 27, CIFAR-10 Batch 1:  \n",
      "Loss: 0.8853704333305359 accuracy: 0.6967821717262268\n",
      "\n",
      "Validation accuracy: 0.6435999870300293\n",
      "Epoch 27, CIFAR-10 Batch 2:  \n",
      "Loss: 0.8550389409065247 accuracy: 0.7128713130950928\n",
      "\n",
      "Validation accuracy: 0.645799994468689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27, CIFAR-10 Batch 3:  \n",
      "Loss: 0.8242861032485962 accuracy: 0.7215346693992615\n",
      "\n",
      "Validation accuracy: 0.6444000005722046\n",
      "Epoch 27, CIFAR-10 Batch 4:  \n",
      "Loss: 0.8550554513931274 accuracy: 0.7202970385551453\n",
      "\n",
      "Validation accuracy: 0.6471999883651733\n",
      "Epoch 27, CIFAR-10 Batch 5:  \n",
      "Loss: 0.8360706567764282 accuracy: 0.728960394859314\n",
      "\n",
      "Validation accuracy: 0.6448000073432922\n",
      "Epoch 28, CIFAR-10 Batch 1:  \n",
      "Loss: 0.8687334060668945 accuracy: 0.7153465151786804\n",
      "\n",
      "Validation accuracy: 0.6478000283241272\n",
      "Epoch 28, CIFAR-10 Batch 2:  \n",
      "Loss: 0.8432934284210205 accuracy: 0.7165841460227966\n",
      "\n",
      "Validation accuracy: 0.652999997138977\n",
      "Epoch 28, CIFAR-10 Batch 3:  \n",
      "Loss: 0.8162109851837158 accuracy: 0.719059407711029\n",
      "\n",
      "Validation accuracy: 0.63919997215271\n",
      "Epoch 28, CIFAR-10 Batch 4:  \n",
      "Loss: 0.84967041015625 accuracy: 0.7141088843345642\n",
      "\n",
      "Validation accuracy: 0.6488000154495239\n",
      "Epoch 28, CIFAR-10 Batch 5:  \n",
      "Loss: 0.8383243680000305 accuracy: 0.7314356565475464\n",
      "\n",
      "Validation accuracy: 0.6444000005722046\n",
      "Epoch 29, CIFAR-10 Batch 1:  \n",
      "Loss: 0.8571393489837646 accuracy: 0.7215346693992615\n",
      "\n",
      "Validation accuracy: 0.6466000080108643\n",
      "Epoch 29, CIFAR-10 Batch 2:  \n",
      "Loss: 0.8556066155433655 accuracy: 0.7091584205627441\n",
      "\n",
      "Validation accuracy: 0.640999972820282\n",
      "Epoch 29, CIFAR-10 Batch 3:  \n",
      "Loss: 0.8060963153839111 accuracy: 0.7202970385551453\n",
      "\n",
      "Validation accuracy: 0.640999972820282\n",
      "Epoch 29, CIFAR-10 Batch 4:  \n",
      "Loss: 0.8403604626655579 accuracy: 0.7141088843345642\n",
      "\n",
      "Validation accuracy: 0.6478000283241272\n",
      "Epoch 29, CIFAR-10 Batch 5:  \n",
      "Loss: 0.8162531852722168 accuracy: 0.7475247383117676\n",
      "\n",
      "Validation accuracy: 0.6467999815940857\n",
      "Epoch 30, CIFAR-10 Batch 1:  \n",
      "Loss: 0.8576310873031616 accuracy: 0.7141088843345642\n",
      "\n",
      "Validation accuracy: 0.6462000012397766\n",
      "Epoch 30, CIFAR-10 Batch 2:  \n",
      "Loss: 0.8283219337463379 accuracy: 0.7042078971862793\n",
      "\n",
      "Validation accuracy: 0.6470000147819519\n",
      "Epoch 30, CIFAR-10 Batch 3:  \n",
      "Loss: 0.801573634147644 accuracy: 0.7091584205627441\n",
      "\n",
      "Validation accuracy: 0.644599974155426\n",
      "Epoch 30, CIFAR-10 Batch 4:  \n",
      "Loss: 0.8308563828468323 accuracy: 0.7227723002433777\n",
      "\n",
      "Validation accuracy: 0.6460000276565552\n",
      "Epoch 30, CIFAR-10 Batch 5:  \n",
      "Loss: 0.7998758554458618 accuracy: 0.7450494766235352\n",
      "\n",
      "Validation accuracy: 0.6496000289916992\n",
      "Epoch 31, CIFAR-10 Batch 1:  \n",
      "Loss: 0.8254824876785278 accuracy: 0.7277227640151978\n",
      "\n",
      "Validation accuracy: 0.6552000045776367\n",
      "Epoch 31, CIFAR-10 Batch 2:  \n",
      "Loss: 0.8107520341873169 accuracy: 0.7103960514068604\n",
      "\n",
      "Validation accuracy: 0.6521999835968018\n",
      "Epoch 31, CIFAR-10 Batch 3:  \n",
      "Loss: 0.7878851294517517 accuracy: 0.7215346693992615\n",
      "\n",
      "Validation accuracy: 0.6484000086784363\n",
      "Epoch 31, CIFAR-10 Batch 4:  \n",
      "Loss: 0.8072320222854614 accuracy: 0.7202970385551453\n",
      "\n",
      "Validation accuracy: 0.6535999774932861\n",
      "Epoch 31, CIFAR-10 Batch 5:  \n",
      "Loss: 0.7825542688369751 accuracy: 0.75\n",
      "\n",
      "Validation accuracy: 0.6520000100135803\n",
      "Epoch 32, CIFAR-10 Batch 1:  \n",
      "Loss: 0.8207494020462036 accuracy: 0.7240098714828491\n",
      "\n",
      "Validation accuracy: 0.6547999978065491\n",
      "Epoch 32, CIFAR-10 Batch 2:  \n",
      "Loss: 0.8081473708152771 accuracy: 0.7215346693992615\n",
      "\n",
      "Validation accuracy: 0.6565999984741211\n",
      "Epoch 32, CIFAR-10 Batch 3:  \n",
      "Loss: 0.8069971203804016 accuracy: 0.7227723002433777\n",
      "\n",
      "Validation accuracy: 0.6366000175476074\n",
      "Epoch 32, CIFAR-10 Batch 4:  \n",
      "Loss: 0.8053773045539856 accuracy: 0.7339109182357788\n",
      "\n",
      "Validation accuracy: 0.6535999774932861\n",
      "Epoch 32, CIFAR-10 Batch 5:  \n",
      "Loss: 0.7868584990501404 accuracy: 0.7388613820075989\n",
      "\n",
      "Validation accuracy: 0.6430000066757202\n",
      "Epoch 33, CIFAR-10 Batch 1:  \n",
      "Loss: 0.8063088059425354 accuracy: 0.7376237511634827\n",
      "\n",
      "Validation accuracy: 0.6579999923706055\n",
      "Epoch 33, CIFAR-10 Batch 2:  \n",
      "Loss: 0.7907502055168152 accuracy: 0.7339109182357788\n",
      "\n",
      "Validation accuracy: 0.6582000255584717\n",
      "Epoch 33, CIFAR-10 Batch 3:  \n",
      "Loss: 0.7846611738204956 accuracy: 0.7252475023269653\n",
      "\n",
      "Validation accuracy: 0.640999972820282\n",
      "Epoch 33, CIFAR-10 Batch 4:  \n",
      "Loss: 0.7963030338287354 accuracy: 0.7314356565475464\n",
      "\n",
      "Validation accuracy: 0.6570000052452087\n",
      "Epoch 33, CIFAR-10 Batch 5:  \n",
      "Loss: 0.7642002105712891 accuracy: 0.7537128925323486\n",
      "\n",
      "Validation accuracy: 0.6561999917030334\n",
      "Epoch 34, CIFAR-10 Batch 1:  \n",
      "Loss: 0.7974121570587158 accuracy: 0.7376237511634827\n",
      "\n",
      "Validation accuracy: 0.6603999733924866\n",
      "Epoch 34, CIFAR-10 Batch 2:  \n",
      "Loss: 0.792324960231781 accuracy: 0.7400990128517151\n",
      "\n",
      "Validation accuracy: 0.6567999720573425\n",
      "Epoch 34, CIFAR-10 Batch 3:  \n",
      "Loss: 0.7741045951843262 accuracy: 0.7301980257034302\n",
      "\n",
      "Validation accuracy: 0.6399999856948853\n",
      "Epoch 34, CIFAR-10 Batch 4:  \n",
      "Loss: 0.7856162190437317 accuracy: 0.7400990128517151\n",
      "\n",
      "Validation accuracy: 0.6528000235557556\n",
      "Epoch 34, CIFAR-10 Batch 5:  \n",
      "Loss: 0.7510269284248352 accuracy: 0.7561880946159363\n",
      "\n",
      "Validation accuracy: 0.6571999788284302\n",
      "Epoch 35, CIFAR-10 Batch 1:  \n",
      "Loss: 0.7918201088905334 accuracy: 0.7339109182357788\n",
      "\n",
      "Validation accuracy: 0.6614000201225281\n",
      "Epoch 35, CIFAR-10 Batch 2:  \n",
      "Loss: 0.7836660146713257 accuracy: 0.7339109182357788\n",
      "\n",
      "Validation accuracy: 0.6600000262260437\n",
      "Epoch 35, CIFAR-10 Batch 3:  \n",
      "Loss: 0.7649571895599365 accuracy: 0.7413366436958313\n",
      "\n",
      "Validation accuracy: 0.6449999809265137\n",
      "Epoch 35, CIFAR-10 Batch 4:  \n",
      "Loss: 0.7721173763275146 accuracy: 0.7400990128517151\n",
      "\n",
      "Validation accuracy: 0.6574000120162964\n",
      "Epoch 35, CIFAR-10 Batch 5:  \n",
      "Loss: 0.7452144622802734 accuracy: 0.7549505233764648\n",
      "\n",
      "Validation accuracy: 0.656000018119812\n",
      "Epoch 36, CIFAR-10 Batch 1:  \n",
      "Loss: 0.7773188352584839 accuracy: 0.7301980257034302\n",
      "\n",
      "Validation accuracy: 0.6621999740600586\n",
      "Epoch 36, CIFAR-10 Batch 2:  \n",
      "Loss: 0.7632350921630859 accuracy: 0.7438119053840637\n",
      "\n",
      "Validation accuracy: 0.6625999808311462\n",
      "Epoch 36, CIFAR-10 Batch 3:  \n",
      "Loss: 0.7475622892379761 accuracy: 0.7425742745399475\n",
      "\n",
      "Validation accuracy: 0.647599995136261\n",
      "Epoch 36, CIFAR-10 Batch 4:  \n",
      "Loss: 0.7611818313598633 accuracy: 0.7450494766235352\n",
      "\n",
      "Validation accuracy: 0.6600000262260437\n",
      "Epoch 36, CIFAR-10 Batch 5:  \n",
      "Loss: 0.7309864163398743 accuracy: 0.7698019742965698\n",
      "\n",
      "Validation accuracy: 0.6607999801635742\n",
      "Epoch 37, CIFAR-10 Batch 1:  \n",
      "Loss: 0.7714998126029968 accuracy: 0.7438119053840637\n",
      "\n",
      "Validation accuracy: 0.6579999923706055\n",
      "Epoch 37, CIFAR-10 Batch 2:  \n",
      "Loss: 0.7537508606910706 accuracy: 0.7475247383117676\n",
      "\n",
      "Validation accuracy: 0.6656000018119812\n",
      "Epoch 37, CIFAR-10 Batch 3:  \n",
      "Loss: 0.7405519485473633 accuracy: 0.7438119053840637\n",
      "\n",
      "Validation accuracy: 0.6520000100135803\n",
      "Epoch 37, CIFAR-10 Batch 4:  \n",
      "Loss: 0.7528762221336365 accuracy: 0.7512376308441162\n",
      "\n",
      "Validation accuracy: 0.6597999930381775\n",
      "Epoch 37, CIFAR-10 Batch 5:  \n",
      "Loss: 0.7251092791557312 accuracy: 0.7623762488365173\n",
      "\n",
      "Validation accuracy: 0.6618000268936157\n",
      "Epoch 38, CIFAR-10 Batch 1:  \n",
      "Loss: 0.7621411085128784 accuracy: 0.75\n",
      "\n",
      "Validation accuracy: 0.6582000255584717\n",
      "Epoch 38, CIFAR-10 Batch 2:  \n",
      "Loss: 0.7415547370910645 accuracy: 0.7462871074676514\n",
      "\n",
      "Validation accuracy: 0.6664000153541565\n",
      "Epoch 38, CIFAR-10 Batch 3:  \n",
      "Loss: 0.7578394412994385 accuracy: 0.7202970385551453\n",
      "\n",
      "Validation accuracy: 0.6471999883651733\n",
      "Epoch 38, CIFAR-10 Batch 4:  \n",
      "Loss: 0.7430440783500671 accuracy: 0.7586633563041687\n",
      "\n",
      "Validation accuracy: 0.6610000133514404\n",
      "Epoch 38, CIFAR-10 Batch 5:  \n",
      "Loss: 0.7232964634895325 accuracy: 0.7722772359848022\n",
      "\n",
      "Validation accuracy: 0.6592000126838684\n",
      "Epoch 39, CIFAR-10 Batch 1:  \n",
      "Loss: 0.7594985961914062 accuracy: 0.7487623691558838\n",
      "\n",
      "Validation accuracy: 0.6647999882698059\n",
      "Epoch 39, CIFAR-10 Batch 2:  \n",
      "Loss: 0.7512147426605225 accuracy: 0.7400990128517151\n",
      "\n",
      "Validation accuracy: 0.6643999814987183\n",
      "Epoch 39, CIFAR-10 Batch 3:  \n",
      "Loss: 0.7291634678840637 accuracy: 0.7586633563041687\n",
      "\n",
      "Validation accuracy: 0.6496000289916992\n",
      "Epoch 39, CIFAR-10 Batch 4:  \n",
      "Loss: 0.758547842502594 accuracy: 0.7586633563041687\n",
      "\n",
      "Validation accuracy: 0.6583999991416931\n",
      "Epoch 39, CIFAR-10 Batch 5:  \n",
      "Loss: 0.7149397134780884 accuracy: 0.7673267126083374\n",
      "\n",
      "Validation accuracy: 0.6610000133514404\n",
      "Epoch 40, CIFAR-10 Batch 1:  \n",
      "Loss: 0.7632431387901306 accuracy: 0.7388613820075989\n",
      "\n",
      "Validation accuracy: 0.6592000126838684\n",
      "Epoch 40, CIFAR-10 Batch 2:  \n",
      "Loss: 0.7342384457588196 accuracy: 0.7561880946159363\n",
      "\n",
      "Validation accuracy: 0.6656000018119812\n",
      "Epoch 40, CIFAR-10 Batch 3:  \n",
      "Loss: 0.7129278779029846 accuracy: 0.7611386179924011\n",
      "\n",
      "Validation accuracy: 0.6592000126838684\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40, CIFAR-10 Batch 4:  \n",
      "Loss: 0.7412063479423523 accuracy: 0.7623762488365173\n",
      "\n",
      "Validation accuracy: 0.6589999794960022\n",
      "Epoch 40, CIFAR-10 Batch 5:  \n",
      "Loss: 0.7174606323242188 accuracy: 0.7735148668289185\n",
      "\n",
      "Validation accuracy: 0.6606000065803528\n",
      "Epoch 41, CIFAR-10 Batch 1:  \n",
      "Loss: 0.7426100373268127 accuracy: 0.7512376308441162\n",
      "\n",
      "Validation accuracy: 0.6665999889373779\n",
      "Epoch 41, CIFAR-10 Batch 2:  \n",
      "Loss: 0.7295526266098022 accuracy: 0.7537128925323486\n",
      "\n",
      "Validation accuracy: 0.6654000282287598\n",
      "Epoch 41, CIFAR-10 Batch 3:  \n",
      "Loss: 0.7214812636375427 accuracy: 0.7475247383117676\n",
      "\n",
      "Validation accuracy: 0.6574000120162964\n",
      "Epoch 41, CIFAR-10 Batch 4:  \n",
      "Loss: 0.7442969083786011 accuracy: 0.7586633563041687\n",
      "\n",
      "Validation accuracy: 0.6600000262260437\n",
      "Epoch 41, CIFAR-10 Batch 5:  \n",
      "Loss: 0.7133414149284363 accuracy: 0.7747524976730347\n",
      "\n",
      "Validation accuracy: 0.6601999998092651\n",
      "Epoch 42, CIFAR-10 Batch 1:  \n",
      "Loss: 0.7330732941627502 accuracy: 0.7537128925323486\n",
      "\n",
      "Validation accuracy: 0.6682000160217285\n",
      "Epoch 42, CIFAR-10 Batch 2:  \n",
      "Loss: 0.7164062857627869 accuracy: 0.7537128925323486\n",
      "\n",
      "Validation accuracy: 0.6611999869346619\n",
      "Epoch 42, CIFAR-10 Batch 3:  \n",
      "Loss: 0.6938597559928894 accuracy: 0.7821782231330872\n",
      "\n",
      "Validation accuracy: 0.6638000011444092\n",
      "Epoch 42, CIFAR-10 Batch 4:  \n",
      "Loss: 0.7257742285728455 accuracy: 0.7611386179924011\n",
      "\n",
      "Validation accuracy: 0.6656000018119812\n",
      "Epoch 42, CIFAR-10 Batch 5:  \n",
      "Loss: 0.7053968906402588 accuracy: 0.7685643434524536\n",
      "\n",
      "Validation accuracy: 0.6628000140190125\n",
      "Epoch 43, CIFAR-10 Batch 1:  \n",
      "Loss: 0.7297324538230896 accuracy: 0.7487623691558838\n",
      "\n",
      "Validation accuracy: 0.6705999970436096\n",
      "Epoch 43, CIFAR-10 Batch 2:  \n",
      "Loss: 0.7125383615493774 accuracy: 0.7462871074676514\n",
      "\n",
      "Validation accuracy: 0.6686000227928162\n",
      "Epoch 43, CIFAR-10 Batch 3:  \n",
      "Loss: 0.6718511581420898 accuracy: 0.7846534848213196\n",
      "\n",
      "Validation accuracy: 0.6647999882698059\n",
      "Epoch 43, CIFAR-10 Batch 4:  \n",
      "Loss: 0.6970793008804321 accuracy: 0.780940592288971\n",
      "\n",
      "Validation accuracy: 0.6705999970436096\n",
      "Epoch 43, CIFAR-10 Batch 5:  \n",
      "Loss: 0.6723564863204956 accuracy: 0.7797029614448547\n",
      "\n",
      "Validation accuracy: 0.6723999977111816\n",
      "Epoch 44, CIFAR-10 Batch 1:  \n",
      "Loss: 0.7196494340896606 accuracy: 0.7487623691558838\n",
      "\n",
      "Validation accuracy: 0.6725999712944031\n",
      "Epoch 44, CIFAR-10 Batch 2:  \n",
      "Loss: 0.7088930606842041 accuracy: 0.7574257254600525\n",
      "\n",
      "Validation accuracy: 0.66839998960495\n",
      "Epoch 44, CIFAR-10 Batch 3:  \n",
      "Loss: 0.688750147819519 accuracy: 0.7599009871482849\n",
      "\n",
      "Validation accuracy: 0.6606000065803528\n",
      "Epoch 44, CIFAR-10 Batch 4:  \n",
      "Loss: 0.6990112662315369 accuracy: 0.7735148668289185\n",
      "\n",
      "Validation accuracy: 0.6696000099182129\n",
      "Epoch 44, CIFAR-10 Batch 5:  \n",
      "Loss: 0.6700277328491211 accuracy: 0.7846534848213196\n",
      "\n",
      "Validation accuracy: 0.6697999835014343\n",
      "Epoch 45, CIFAR-10 Batch 1:  \n",
      "Loss: 0.7275865077972412 accuracy: 0.7450494766235352\n",
      "\n",
      "Validation accuracy: 0.6633999943733215\n",
      "Epoch 45, CIFAR-10 Batch 2:  \n",
      "Loss: 0.6975961923599243 accuracy: 0.7574257254600525\n",
      "\n",
      "Validation accuracy: 0.6672000288963318\n",
      "Epoch 45, CIFAR-10 Batch 3:  \n",
      "Loss: 0.6630584597587585 accuracy: 0.7846534848213196\n",
      "\n",
      "Validation accuracy: 0.6693999767303467\n",
      "Epoch 45, CIFAR-10 Batch 4:  \n",
      "Loss: 0.6864644885063171 accuracy: 0.7933168411254883\n",
      "\n",
      "Validation accuracy: 0.6722000241279602\n",
      "Epoch 45, CIFAR-10 Batch 5:  \n",
      "Loss: 0.6715545654296875 accuracy: 0.7896039485931396\n",
      "\n",
      "Validation accuracy: 0.6704000234603882\n",
      "Epoch 46, CIFAR-10 Batch 1:  \n",
      "Loss: 0.7061128616333008 accuracy: 0.7586633563041687\n",
      "\n",
      "Validation accuracy: 0.6718000173568726\n",
      "Epoch 46, CIFAR-10 Batch 2:  \n",
      "Loss: 0.6874054074287415 accuracy: 0.7549505233764648\n",
      "\n",
      "Validation accuracy: 0.6765999794006348\n",
      "Epoch 46, CIFAR-10 Batch 3:  \n",
      "Loss: 0.6650077700614929 accuracy: 0.771039605140686\n",
      "\n",
      "Validation accuracy: 0.6714000105857849\n",
      "Epoch 46, CIFAR-10 Batch 4:  \n",
      "Loss: 0.6824709177017212 accuracy: 0.7883663177490234\n",
      "\n",
      "Validation accuracy: 0.6718000173568726\n",
      "Epoch 46, CIFAR-10 Batch 5:  \n",
      "Loss: 0.6524092555046082 accuracy: 0.7945544719696045\n",
      "\n",
      "Validation accuracy: 0.6714000105857849\n",
      "Epoch 47, CIFAR-10 Batch 1:  \n",
      "Loss: 0.6943639516830444 accuracy: 0.7561880946159363\n",
      "\n",
      "Validation accuracy: 0.676800012588501\n",
      "Epoch 47, CIFAR-10 Batch 2:  \n",
      "Loss: 0.6818870902061462 accuracy: 0.7698019742965698\n",
      "\n",
      "Validation accuracy: 0.6741999983787537\n",
      "Epoch 47, CIFAR-10 Batch 3:  \n",
      "Loss: 0.6635978817939758 accuracy: 0.7772276997566223\n",
      "\n",
      "Validation accuracy: 0.6769999861717224\n",
      "Epoch 47, CIFAR-10 Batch 4:  \n",
      "Loss: 0.6946485042572021 accuracy: 0.780940592288971\n",
      "\n",
      "Validation accuracy: 0.6632000207901001\n",
      "Epoch 47, CIFAR-10 Batch 5:  \n",
      "Loss: 0.6581467986106873 accuracy: 0.7896039485931396\n",
      "\n",
      "Validation accuracy: 0.6696000099182129\n",
      "Epoch 48, CIFAR-10 Batch 1:  \n",
      "Loss: 0.6801023483276367 accuracy: 0.7599009871482849\n",
      "\n",
      "Validation accuracy: 0.675599992275238\n",
      "Epoch 48, CIFAR-10 Batch 2:  \n",
      "Loss: 0.6835470795631409 accuracy: 0.7561880946159363\n",
      "\n",
      "Validation accuracy: 0.6647999882698059\n",
      "Epoch 48, CIFAR-10 Batch 3:  \n",
      "Loss: 0.6549155116081238 accuracy: 0.7772276997566223\n",
      "\n",
      "Validation accuracy: 0.6732000112533569\n",
      "Epoch 48, CIFAR-10 Batch 4:  \n",
      "Loss: 0.6738486886024475 accuracy: 0.7945544719696045\n",
      "\n",
      "Validation accuracy: 0.6740000247955322\n",
      "Epoch 48, CIFAR-10 Batch 5:  \n",
      "Loss: 0.6624786853790283 accuracy: 0.7797029614448547\n",
      "\n",
      "Validation accuracy: 0.6669999957084656\n",
      "Epoch 49, CIFAR-10 Batch 1:  \n",
      "Loss: 0.678810715675354 accuracy: 0.7623762488365173\n",
      "\n",
      "Validation accuracy: 0.6751999855041504\n",
      "Epoch 49, CIFAR-10 Batch 2:  \n",
      "Loss: 0.6762388348579407 accuracy: 0.7512376308441162\n",
      "\n",
      "Validation accuracy: 0.6705999970436096\n",
      "Epoch 49, CIFAR-10 Batch 3:  \n",
      "Loss: 0.654489278793335 accuracy: 0.7821782231330872\n",
      "\n",
      "Validation accuracy: 0.6704000234603882\n",
      "Epoch 49, CIFAR-10 Batch 4:  \n",
      "Loss: 0.660721480846405 accuracy: 0.7883663177490234\n",
      "\n",
      "Validation accuracy: 0.6751999855041504\n",
      "Epoch 49, CIFAR-10 Batch 5:  \n",
      "Loss: 0.6409746408462524 accuracy: 0.7896039485931396\n",
      "\n",
      "Validation accuracy: 0.673799991607666\n",
      "Epoch 50, CIFAR-10 Batch 1:  \n",
      "Loss: 0.6647445559501648 accuracy: 0.7735148668289185\n",
      "\n",
      "Validation accuracy: 0.6787999868392944\n",
      "Epoch 50, CIFAR-10 Batch 2:  \n",
      "Loss: 0.6750360727310181 accuracy: 0.7561880946159363\n",
      "\n",
      "Validation accuracy: 0.6686000227928162\n",
      "Epoch 50, CIFAR-10 Batch 3:  \n",
      "Loss: 0.6489669680595398 accuracy: 0.7920792102813721\n",
      "\n",
      "Validation accuracy: 0.6714000105857849\n",
      "Epoch 50, CIFAR-10 Batch 4:  \n",
      "Loss: 0.6835440993309021 accuracy: 0.780940592288971\n",
      "\n",
      "Validation accuracy: 0.6674000024795532\n",
      "Epoch 50, CIFAR-10 Batch 5:  \n",
      "Loss: 0.6546869277954102 accuracy: 0.7821782231330872\n",
      "\n",
      "Validation accuracy: 0.6668000221252441\n",
      "Epoch 51, CIFAR-10 Batch 1:  \n",
      "Loss: 0.6668392419815063 accuracy: 0.7722772359848022\n",
      "\n",
      "Validation accuracy: 0.6779999732971191\n",
      "Epoch 51, CIFAR-10 Batch 2:  \n",
      "Loss: 0.6481414437294006 accuracy: 0.7834158539772034\n",
      "\n",
      "Validation accuracy: 0.6741999983787537\n",
      "Epoch 51, CIFAR-10 Batch 3:  \n",
      "Loss: 0.6207389235496521 accuracy: 0.7858911156654358\n",
      "\n",
      "Validation accuracy: 0.6818000078201294\n",
      "Epoch 51, CIFAR-10 Batch 4:  \n",
      "Loss: 0.6622130870819092 accuracy: 0.7945544719696045\n",
      "\n",
      "Validation accuracy: 0.6714000105857849\n",
      "Epoch 51, CIFAR-10 Batch 5:  \n",
      "Loss: 0.6440610289573669 accuracy: 0.7896039485931396\n",
      "\n",
      "Validation accuracy: 0.6710000038146973\n",
      "Epoch 52, CIFAR-10 Batch 1:  \n",
      "Loss: 0.6771076917648315 accuracy: 0.7784653306007385\n",
      "\n",
      "Validation accuracy: 0.6678000092506409\n",
      "Epoch 52, CIFAR-10 Batch 2:  \n",
      "Loss: 0.6516792178153992 accuracy: 0.7722772359848022\n",
      "\n",
      "Validation accuracy: 0.6736000180244446\n",
      "Epoch 52, CIFAR-10 Batch 3:  \n",
      "Loss: 0.6257999539375305 accuracy: 0.7970296740531921\n",
      "\n",
      "Validation accuracy: 0.6773999929428101\n",
      "Epoch 52, CIFAR-10 Batch 4:  \n",
      "Loss: 0.635206937789917 accuracy: 0.7957921028137207\n",
      "\n",
      "Validation accuracy: 0.6797999739646912\n",
      "Epoch 52, CIFAR-10 Batch 5:  \n",
      "Loss: 0.600002646446228 accuracy: 0.8032178282737732\n",
      "\n",
      "Validation accuracy: 0.6808000206947327\n",
      "Epoch 53, CIFAR-10 Batch 1:  \n",
      "Loss: 0.6518681645393372 accuracy: 0.7784653306007385\n",
      "\n",
      "Validation accuracy: 0.6836000084877014\n",
      "Epoch 53, CIFAR-10 Batch 2:  \n",
      "Loss: 0.6589628458023071 accuracy: 0.7648515105247498\n",
      "\n",
      "Validation accuracy: 0.6705999970436096\n",
      "Epoch 53, CIFAR-10 Batch 3:  \n",
      "Loss: 0.6430486440658569 accuracy: 0.7834158539772034\n",
      "\n",
      "Validation accuracy: 0.6729999780654907\n",
      "Epoch 53, CIFAR-10 Batch 4:  \n",
      "Loss: 0.6341723203659058 accuracy: 0.7982673048973083\n",
      "\n",
      "Validation accuracy: 0.680400013923645\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53, CIFAR-10 Batch 5:  \n",
      "Loss: 0.6122899055480957 accuracy: 0.7982673048973083\n",
      "\n",
      "Validation accuracy: 0.6797999739646912\n",
      "Epoch 54, CIFAR-10 Batch 1:  \n",
      "Loss: 0.6428954005241394 accuracy: 0.7735148668289185\n",
      "\n",
      "Validation accuracy: 0.6787999868392944\n",
      "Epoch 54, CIFAR-10 Batch 2:  \n",
      "Loss: 0.6711251139640808 accuracy: 0.7586633563041687\n",
      "\n",
      "Validation accuracy: 0.6668000221252441\n",
      "Epoch 54, CIFAR-10 Batch 3:  \n",
      "Loss: 0.5991590619087219 accuracy: 0.8069307208061218\n",
      "\n",
      "Validation accuracy: 0.6848000288009644\n",
      "Epoch 54, CIFAR-10 Batch 4:  \n",
      "Loss: 0.667917788028717 accuracy: 0.771039605140686\n",
      "\n",
      "Validation accuracy: 0.6690000295639038\n",
      "Epoch 54, CIFAR-10 Batch 5:  \n",
      "Loss: 0.6087024807929993 accuracy: 0.801980197429657\n",
      "\n",
      "Validation accuracy: 0.678600013256073\n",
      "Epoch 55, CIFAR-10 Batch 1:  \n",
      "Loss: 0.634211003780365 accuracy: 0.7883663177490234\n",
      "\n",
      "Validation accuracy: 0.6837999820709229\n",
      "Epoch 55, CIFAR-10 Batch 2:  \n",
      "Loss: 0.6430205702781677 accuracy: 0.7735148668289185\n",
      "\n",
      "Validation accuracy: 0.6801999807357788\n",
      "Epoch 55, CIFAR-10 Batch 3:  \n",
      "Loss: 0.597569465637207 accuracy: 0.7970296740531921\n",
      "\n",
      "Validation accuracy: 0.6791999936103821\n",
      "Epoch 55, CIFAR-10 Batch 4:  \n",
      "Loss: 0.6547216773033142 accuracy: 0.7846534848213196\n",
      "\n",
      "Validation accuracy: 0.6741999983787537\n",
      "Epoch 55, CIFAR-10 Batch 5:  \n",
      "Loss: 0.6136777400970459 accuracy: 0.7982673048973083\n",
      "\n",
      "Validation accuracy: 0.6740000247955322\n",
      "Epoch 56, CIFAR-10 Batch 1:  \n",
      "Loss: 0.6343702077865601 accuracy: 0.7908415794372559\n",
      "\n",
      "Validation accuracy: 0.6850000023841858\n",
      "Epoch 56, CIFAR-10 Batch 2:  \n",
      "Loss: 0.6212426424026489 accuracy: 0.7735148668289185\n",
      "\n",
      "Validation accuracy: 0.6823999881744385\n",
      "Epoch 56, CIFAR-10 Batch 3:  \n",
      "Loss: 0.5859892964363098 accuracy: 0.8069307208061218\n",
      "\n",
      "Validation accuracy: 0.6845999956130981\n",
      "Epoch 56, CIFAR-10 Batch 4:  \n",
      "Loss: 0.6272238492965698 accuracy: 0.7920792102813721\n",
      "\n",
      "Validation accuracy: 0.6818000078201294\n",
      "Epoch 56, CIFAR-10 Batch 5:  \n",
      "Loss: 0.6044986844062805 accuracy: 0.7970296740531921\n",
      "\n",
      "Validation accuracy: 0.676800012588501\n",
      "Epoch 57, CIFAR-10 Batch 1:  \n",
      "Loss: 0.6137381792068481 accuracy: 0.7933168411254883\n",
      "\n",
      "Validation accuracy: 0.6837999820709229\n",
      "Epoch 57, CIFAR-10 Batch 2:  \n",
      "Loss: 0.6236447691917419 accuracy: 0.7846534848213196\n",
      "\n",
      "Validation accuracy: 0.6814000010490417\n",
      "Epoch 57, CIFAR-10 Batch 3:  \n",
      "Loss: 0.5890847444534302 accuracy: 0.8032178282737732\n",
      "\n",
      "Validation accuracy: 0.6782000064849854\n",
      "Epoch 57, CIFAR-10 Batch 4:  \n",
      "Loss: 0.6322040557861328 accuracy: 0.7933168411254883\n",
      "\n",
      "Validation accuracy: 0.6743999719619751\n",
      "Epoch 57, CIFAR-10 Batch 5:  \n",
      "Loss: 0.5824719667434692 accuracy: 0.8056930899620056\n",
      "\n",
      "Validation accuracy: 0.6848000288009644\n",
      "Epoch 58, CIFAR-10 Batch 1:  \n",
      "Loss: 0.6319685578346252 accuracy: 0.7970296740531921\n",
      "\n",
      "Validation accuracy: 0.6818000078201294\n",
      "Epoch 58, CIFAR-10 Batch 2:  \n",
      "Loss: 0.6421841382980347 accuracy: 0.7660890817642212\n",
      "\n",
      "Validation accuracy: 0.6697999835014343\n",
      "Epoch 58, CIFAR-10 Batch 3:  \n",
      "Loss: 0.5838256478309631 accuracy: 0.8069307208061218\n",
      "\n",
      "Validation accuracy: 0.6819999814033508\n",
      "Epoch 58, CIFAR-10 Batch 4:  \n",
      "Loss: 0.6128733158111572 accuracy: 0.8094059228897095\n",
      "\n",
      "Validation accuracy: 0.6812000274658203\n",
      "Epoch 58, CIFAR-10 Batch 5:  \n",
      "Loss: 0.6147628426551819 accuracy: 0.7933168411254883\n",
      "\n",
      "Validation accuracy: 0.6764000058174133\n",
      "Epoch 59, CIFAR-10 Batch 1:  \n",
      "Loss: 0.6384479999542236 accuracy: 0.7735148668289185\n",
      "\n",
      "Validation accuracy: 0.6772000193595886\n",
      "Epoch 59, CIFAR-10 Batch 2:  \n",
      "Loss: 0.6567992568016052 accuracy: 0.7698019742965698\n",
      "\n",
      "Validation accuracy: 0.6705999970436096\n",
      "Epoch 59, CIFAR-10 Batch 3:  \n",
      "Loss: 0.5947776436805725 accuracy: 0.7995049357414246\n",
      "\n",
      "Validation accuracy: 0.682200014591217\n",
      "Epoch 59, CIFAR-10 Batch 4:  \n",
      "Loss: 0.6193153262138367 accuracy: 0.7908415794372559\n",
      "\n",
      "Validation accuracy: 0.6711999773979187\n",
      "Epoch 59, CIFAR-10 Batch 5:  \n",
      "Loss: 0.5776201486587524 accuracy: 0.8131188154220581\n",
      "\n",
      "Validation accuracy: 0.6826000213623047\n",
      "Epoch 60, CIFAR-10 Batch 1:  \n",
      "Loss: 0.605059027671814 accuracy: 0.7945544719696045\n",
      "\n",
      "Validation accuracy: 0.6854000091552734\n",
      "Epoch 60, CIFAR-10 Batch 2:  \n",
      "Loss: 0.6270753741264343 accuracy: 0.7908415794372559\n",
      "\n",
      "Validation accuracy: 0.6761999726295471\n",
      "Epoch 60, CIFAR-10 Batch 3:  \n",
      "Loss: 0.5880475044250488 accuracy: 0.8056930899620056\n",
      "\n",
      "Validation accuracy: 0.6823999881744385\n",
      "Epoch 60, CIFAR-10 Batch 4:  \n",
      "Loss: 0.5856513381004333 accuracy: 0.8118811845779419\n",
      "\n",
      "Validation accuracy: 0.6791999936103821\n",
      "Epoch 60, CIFAR-10 Batch 5:  \n",
      "Loss: 0.5848994851112366 accuracy: 0.8069307208061218\n",
      "\n",
      "Validation accuracy: 0.6815999746322632\n",
      "Epoch 61, CIFAR-10 Batch 1:  \n",
      "Loss: 0.6089324951171875 accuracy: 0.7883663177490234\n",
      "\n",
      "Validation accuracy: 0.6787999868392944\n",
      "Epoch 61, CIFAR-10 Batch 2:  \n",
      "Loss: 0.6092270016670227 accuracy: 0.7834158539772034\n",
      "\n",
      "Validation accuracy: 0.6833999752998352\n",
      "Epoch 61, CIFAR-10 Batch 3:  \n",
      "Loss: 0.5676012635231018 accuracy: 0.8056930899620056\n",
      "\n",
      "Validation accuracy: 0.6873999834060669\n",
      "Epoch 61, CIFAR-10 Batch 4:  \n",
      "Loss: 0.599137008190155 accuracy: 0.8007425665855408\n",
      "\n",
      "Validation accuracy: 0.6743999719619751\n",
      "Epoch 61, CIFAR-10 Batch 5:  \n",
      "Loss: 0.5682141780853271 accuracy: 0.8081682920455933\n",
      "\n",
      "Validation accuracy: 0.6848000288009644\n",
      "Epoch 62, CIFAR-10 Batch 1:  \n",
      "Loss: 0.5893223881721497 accuracy: 0.8044554591178894\n",
      "\n",
      "Validation accuracy: 0.6881999969482422\n",
      "Epoch 62, CIFAR-10 Batch 2:  \n",
      "Loss: 0.6050042510032654 accuracy: 0.7908415794372559\n",
      "\n",
      "Validation accuracy: 0.6783999800682068\n",
      "Epoch 62, CIFAR-10 Batch 3:  \n",
      "Loss: 0.5570601224899292 accuracy: 0.8143564462661743\n",
      "\n",
      "Validation accuracy: 0.6894000172615051\n",
      "Epoch 62, CIFAR-10 Batch 4:  \n",
      "Loss: 0.5979132056236267 accuracy: 0.8032178282737732\n",
      "\n",
      "Validation accuracy: 0.6722000241279602\n",
      "Epoch 62, CIFAR-10 Batch 5:  \n",
      "Loss: 0.5565122961997986 accuracy: 0.8118811845779419\n",
      "\n",
      "Validation accuracy: 0.6823999881744385\n",
      "Epoch 63, CIFAR-10 Batch 1:  \n",
      "Loss: 0.5828482508659363 accuracy: 0.8094059228897095\n",
      "\n",
      "Validation accuracy: 0.6887999773025513\n",
      "Epoch 63, CIFAR-10 Batch 2:  \n",
      "Loss: 0.5935734510421753 accuracy: 0.7896039485931396\n",
      "\n",
      "Validation accuracy: 0.6800000071525574\n",
      "Epoch 63, CIFAR-10 Batch 3:  \n",
      "Loss: 0.5486297607421875 accuracy: 0.8205445408821106\n",
      "\n",
      "Validation accuracy: 0.6886000037193298\n",
      "Epoch 63, CIFAR-10 Batch 4:  \n",
      "Loss: 0.5826913714408875 accuracy: 0.8044554591178894\n",
      "\n",
      "Validation accuracy: 0.6809999942779541\n",
      "Epoch 63, CIFAR-10 Batch 5:  \n",
      "Loss: 0.5429205894470215 accuracy: 0.8168317079544067\n",
      "\n",
      "Validation accuracy: 0.6898000240325928\n",
      "Epoch 64, CIFAR-10 Batch 1:  \n",
      "Loss: 0.5867363810539246 accuracy: 0.7970296740531921\n",
      "\n",
      "Validation accuracy: 0.6850000023841858\n",
      "Epoch 64, CIFAR-10 Batch 2:  \n",
      "Loss: 0.6024059057235718 accuracy: 0.7834158539772034\n",
      "\n",
      "Validation accuracy: 0.6790000200271606\n",
      "Epoch 64, CIFAR-10 Batch 3:  \n",
      "Loss: 0.535588800907135 accuracy: 0.8168317079544067\n",
      "\n",
      "Validation accuracy: 0.6880000233650208\n",
      "Epoch 64, CIFAR-10 Batch 4:  \n",
      "Loss: 0.5811935067176819 accuracy: 0.8032178282737732\n",
      "\n",
      "Validation accuracy: 0.6812000274658203\n",
      "Epoch 64, CIFAR-10 Batch 5:  \n",
      "Loss: 0.5371429324150085 accuracy: 0.8279703259468079\n",
      "\n",
      "Validation accuracy: 0.6840000152587891\n",
      "Epoch 65, CIFAR-10 Batch 1:  \n",
      "Loss: 0.5599864721298218 accuracy: 0.8131188154220581\n",
      "\n",
      "Validation accuracy: 0.6881999969482422\n",
      "Epoch 65, CIFAR-10 Batch 2:  \n",
      "Loss: 0.5816953778266907 accuracy: 0.8069307208061218\n",
      "\n",
      "Validation accuracy: 0.6866000294685364\n",
      "Epoch 65, CIFAR-10 Batch 3:  \n",
      "Loss: 0.5319146513938904 accuracy: 0.8193069100379944\n",
      "\n",
      "Validation accuracy: 0.6917999982833862\n",
      "Epoch 65, CIFAR-10 Batch 4:  \n",
      "Loss: 0.5793343186378479 accuracy: 0.8094059228897095\n",
      "\n",
      "Validation accuracy: 0.6790000200271606\n",
      "Epoch 65, CIFAR-10 Batch 5:  \n",
      "Loss: 0.5387002825737 accuracy: 0.8193069100379944\n",
      "\n",
      "Validation accuracy: 0.6850000023841858\n",
      "Epoch 66, CIFAR-10 Batch 1:  \n",
      "Loss: 0.5539268851280212 accuracy: 0.8131188154220581\n",
      "\n",
      "Validation accuracy: 0.6905999779701233\n",
      "Epoch 66, CIFAR-10 Batch 2:  \n",
      "Loss: 0.5876095294952393 accuracy: 0.7920792102813721\n",
      "\n",
      "Validation accuracy: 0.6819999814033508\n",
      "Epoch 66, CIFAR-10 Batch 3:  \n",
      "Loss: 0.543390691280365 accuracy: 0.8155940771102905\n",
      "\n",
      "Validation accuracy: 0.6845999956130981\n",
      "Epoch 66, CIFAR-10 Batch 4:  \n",
      "Loss: 0.5630986094474792 accuracy: 0.8094059228897095\n",
      "\n",
      "Validation accuracy: 0.6854000091552734\n",
      "Epoch 66, CIFAR-10 Batch 5:  \n",
      "Loss: 0.5217279195785522 accuracy: 0.8292078971862793\n",
      "\n",
      "Validation accuracy: 0.6912000179290771\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67, CIFAR-10 Batch 1:  \n",
      "Loss: 0.5513426065444946 accuracy: 0.8081682920455933\n",
      "\n",
      "Validation accuracy: 0.6916000247001648\n",
      "Epoch 67, CIFAR-10 Batch 2:  \n",
      "Loss: 0.574895977973938 accuracy: 0.7945544719696045\n",
      "\n",
      "Validation accuracy: 0.6862000226974487\n",
      "Epoch 67, CIFAR-10 Batch 3:  \n",
      "Loss: 0.5274075269699097 accuracy: 0.8205445408821106\n",
      "\n",
      "Validation accuracy: 0.6886000037193298\n",
      "Epoch 67, CIFAR-10 Batch 4:  \n",
      "Loss: 0.5448395013809204 accuracy: 0.823019802570343\n",
      "\n",
      "Validation accuracy: 0.6908000111579895\n",
      "Epoch 67, CIFAR-10 Batch 5:  \n",
      "Loss: 0.5313806533813477 accuracy: 0.8279703259468079\n",
      "\n",
      "Validation accuracy: 0.6837999820709229\n",
      "Epoch 68, CIFAR-10 Batch 1:  \n",
      "Loss: 0.5484341979026794 accuracy: 0.8081682920455933\n",
      "\n",
      "Validation accuracy: 0.6898000240325928\n",
      "Epoch 68, CIFAR-10 Batch 2:  \n",
      "Loss: 0.5646708011627197 accuracy: 0.8032178282737732\n",
      "\n",
      "Validation accuracy: 0.6833999752998352\n",
      "Epoch 68, CIFAR-10 Batch 3:  \n",
      "Loss: 0.5417526364326477 accuracy: 0.8131188154220581\n",
      "\n",
      "Validation accuracy: 0.6837999820709229\n",
      "Epoch 68, CIFAR-10 Batch 4:  \n",
      "Loss: 0.5562685132026672 accuracy: 0.8094059228897095\n",
      "\n",
      "Validation accuracy: 0.6877999901771545\n",
      "Epoch 68, CIFAR-10 Batch 5:  \n",
      "Loss: 0.5221719145774841 accuracy: 0.8205445408821106\n",
      "\n",
      "Validation accuracy: 0.6866000294685364\n",
      "Epoch 69, CIFAR-10 Batch 1:  \n",
      "Loss: 0.5328171849250793 accuracy: 0.8168317079544067\n",
      "\n",
      "Validation accuracy: 0.6876000165939331\n",
      "Epoch 69, CIFAR-10 Batch 2:  \n",
      "Loss: 0.5819728374481201 accuracy: 0.7982673048973083\n",
      "\n",
      "Validation accuracy: 0.6796000003814697\n",
      "Epoch 69, CIFAR-10 Batch 3:  \n",
      "Loss: 0.5124359726905823 accuracy: 0.8168317079544067\n",
      "\n",
      "Validation accuracy: 0.6912000179290771\n",
      "Epoch 69, CIFAR-10 Batch 4:  \n",
      "Loss: 0.5317422747612 accuracy: 0.8316831588745117\n",
      "\n",
      "Validation accuracy: 0.6926000118255615\n",
      "Epoch 69, CIFAR-10 Batch 5:  \n",
      "Loss: 0.5045740604400635 accuracy: 0.8267326951026917\n",
      "\n",
      "Validation accuracy: 0.6934000253677368\n",
      "Epoch 70, CIFAR-10 Batch 1:  \n",
      "Loss: 0.527534008026123 accuracy: 0.823019802570343\n",
      "\n",
      "Validation accuracy: 0.6908000111579895\n",
      "Epoch 70, CIFAR-10 Batch 2:  \n",
      "Loss: 0.546928882598877 accuracy: 0.8254950642585754\n",
      "\n",
      "Validation accuracy: 0.6868000030517578\n",
      "Epoch 70, CIFAR-10 Batch 3:  \n",
      "Loss: 0.5172203779220581 accuracy: 0.8279703259468079\n",
      "\n",
      "Validation accuracy: 0.6868000030517578\n",
      "Epoch 70, CIFAR-10 Batch 4:  \n",
      "Loss: 0.5337790250778198 accuracy: 0.8193069100379944\n",
      "\n",
      "Validation accuracy: 0.6851999759674072\n",
      "Epoch 70, CIFAR-10 Batch 5:  \n",
      "Loss: 0.500152587890625 accuracy: 0.8279703259468079\n",
      "\n",
      "Validation accuracy: 0.6894000172615051\n",
      "Epoch 71, CIFAR-10 Batch 1:  \n",
      "Loss: 0.5223737359046936 accuracy: 0.8180692791938782\n",
      "\n",
      "Validation accuracy: 0.694599986076355\n",
      "Epoch 71, CIFAR-10 Batch 2:  \n",
      "Loss: 0.547659695148468 accuracy: 0.8094059228897095\n",
      "\n",
      "Validation accuracy: 0.6858000159263611\n",
      "Epoch 71, CIFAR-10 Batch 3:  \n",
      "Loss: 0.4935908317565918 accuracy: 0.8292078971862793\n",
      "\n",
      "Validation accuracy: 0.6941999793052673\n",
      "Epoch 71, CIFAR-10 Batch 4:  \n",
      "Loss: 0.5239830613136292 accuracy: 0.8254950642585754\n",
      "\n",
      "Validation accuracy: 0.6868000030517578\n",
      "Epoch 71, CIFAR-10 Batch 5:  \n",
      "Loss: 0.49644044041633606 accuracy: 0.8292078971862793\n",
      "\n",
      "Validation accuracy: 0.6891999840736389\n",
      "Epoch 72, CIFAR-10 Batch 1:  \n",
      "Loss: 0.5290530920028687 accuracy: 0.8242574334144592\n",
      "\n",
      "Validation accuracy: 0.6836000084877014\n",
      "Epoch 72, CIFAR-10 Batch 2:  \n",
      "Loss: 0.5537907481193542 accuracy: 0.8155940771102905\n",
      "\n",
      "Validation accuracy: 0.6844000220298767\n",
      "Epoch 72, CIFAR-10 Batch 3:  \n",
      "Loss: 0.49773797392845154 accuracy: 0.8242574334144592\n",
      "\n",
      "Validation accuracy: 0.6955999732017517\n",
      "Epoch 72, CIFAR-10 Batch 4:  \n",
      "Loss: 0.5241261124610901 accuracy: 0.8242574334144592\n",
      "\n",
      "Validation accuracy: 0.6901999711990356\n",
      "Epoch 72, CIFAR-10 Batch 5:  \n",
      "Loss: 0.5063859224319458 accuracy: 0.8292078971862793\n",
      "\n",
      "Validation accuracy: 0.6845999956130981\n",
      "Epoch 73, CIFAR-10 Batch 1:  \n",
      "Loss: 0.5202942490577698 accuracy: 0.8168317079544067\n",
      "\n",
      "Validation accuracy: 0.6899999976158142\n",
      "Epoch 73, CIFAR-10 Batch 2:  \n",
      "Loss: 0.5627763271331787 accuracy: 0.8106435537338257\n",
      "\n",
      "Validation accuracy: 0.6826000213623047\n",
      "Epoch 73, CIFAR-10 Batch 3:  \n",
      "Loss: 0.49050235748291016 accuracy: 0.8267326951026917\n",
      "\n",
      "Validation accuracy: 0.6890000104904175\n",
      "Epoch 73, CIFAR-10 Batch 4:  \n",
      "Loss: 0.5390176773071289 accuracy: 0.823019802570343\n",
      "\n",
      "Validation accuracy: 0.6863999962806702\n",
      "Epoch 73, CIFAR-10 Batch 5:  \n",
      "Loss: 0.5233500003814697 accuracy: 0.8205445408821106\n",
      "\n",
      "Validation accuracy: 0.6776000261306763\n",
      "Epoch 74, CIFAR-10 Batch 1:  \n",
      "Loss: 0.5249312520027161 accuracy: 0.8168317079544067\n",
      "\n",
      "Validation accuracy: 0.6919999718666077\n",
      "Epoch 74, CIFAR-10 Batch 2:  \n",
      "Loss: 0.5457338094711304 accuracy: 0.8168317079544067\n",
      "\n",
      "Validation accuracy: 0.6836000084877014\n",
      "Epoch 74, CIFAR-10 Batch 3:  \n",
      "Loss: 0.5083257555961609 accuracy: 0.8193069100379944\n",
      "\n",
      "Validation accuracy: 0.6881999969482422\n",
      "Epoch 74, CIFAR-10 Batch 4:  \n",
      "Loss: 0.5298452973365784 accuracy: 0.8155940771102905\n",
      "\n",
      "Validation accuracy: 0.6812000274658203\n",
      "Epoch 74, CIFAR-10 Batch 5:  \n",
      "Loss: 0.4928429424762726 accuracy: 0.8292078971862793\n",
      "\n",
      "Validation accuracy: 0.6873999834060669\n",
      "Epoch 75, CIFAR-10 Batch 1:  \n",
      "Loss: 0.5136769413948059 accuracy: 0.8304455280303955\n",
      "\n",
      "Validation accuracy: 0.6948000192642212\n",
      "Epoch 75, CIFAR-10 Batch 2:  \n",
      "Loss: 0.5381597280502319 accuracy: 0.8143564462661743\n",
      "\n",
      "Validation accuracy: 0.6855999827384949\n",
      "Epoch 75, CIFAR-10 Batch 3:  \n",
      "Loss: 0.4941328465938568 accuracy: 0.8292078971862793\n",
      "\n",
      "Validation accuracy: 0.6886000037193298\n",
      "Epoch 75, CIFAR-10 Batch 4:  \n",
      "Loss: 0.5185651779174805 accuracy: 0.8180692791938782\n",
      "\n",
      "Validation accuracy: 0.6872000098228455\n",
      "Epoch 75, CIFAR-10 Batch 5:  \n",
      "Loss: 0.48719322681427 accuracy: 0.8316831588745117\n",
      "\n",
      "Validation accuracy: 0.6922000050544739\n",
      "Epoch 76, CIFAR-10 Batch 1:  \n",
      "Loss: 0.5087207555770874 accuracy: 0.8292078971862793\n",
      "\n",
      "Validation accuracy: 0.6931999921798706\n",
      "Epoch 76, CIFAR-10 Batch 2:  \n",
      "Loss: 0.5342113375663757 accuracy: 0.8180692791938782\n",
      "\n",
      "Validation accuracy: 0.6850000023841858\n",
      "Epoch 76, CIFAR-10 Batch 3:  \n",
      "Loss: 0.49800556898117065 accuracy: 0.823019802570343\n",
      "\n",
      "Validation accuracy: 0.6916000247001648\n",
      "Epoch 76, CIFAR-10 Batch 4:  \n",
      "Loss: 0.5213235020637512 accuracy: 0.823019802570343\n",
      "\n",
      "Validation accuracy: 0.6851999759674072\n",
      "Epoch 76, CIFAR-10 Batch 5:  \n",
      "Loss: 0.480192095041275 accuracy: 0.8452970385551453\n",
      "\n",
      "Validation accuracy: 0.6913999915122986\n",
      "Epoch 77, CIFAR-10 Batch 1:  \n",
      "Loss: 0.5087404251098633 accuracy: 0.8304455280303955\n",
      "\n",
      "Validation accuracy: 0.6967999935150146\n",
      "Epoch 77, CIFAR-10 Batch 2:  \n",
      "Loss: 0.5243967771530151 accuracy: 0.8168317079544067\n",
      "\n",
      "Validation accuracy: 0.682200014591217\n",
      "Epoch 77, CIFAR-10 Batch 3:  \n",
      "Loss: 0.4880121946334839 accuracy: 0.8267326951026917\n",
      "\n",
      "Validation accuracy: 0.6886000037193298\n",
      "Epoch 77, CIFAR-10 Batch 4:  \n",
      "Loss: 0.5121928453445435 accuracy: 0.8193069100379944\n",
      "\n",
      "Validation accuracy: 0.6908000111579895\n",
      "Epoch 77, CIFAR-10 Batch 5:  \n",
      "Loss: 0.4710247814655304 accuracy: 0.8403465151786804\n",
      "\n",
      "Validation accuracy: 0.6916000247001648\n",
      "Epoch 78, CIFAR-10 Batch 1:  \n",
      "Loss: 0.5003752112388611 accuracy: 0.8353960514068604\n",
      "\n",
      "Validation accuracy: 0.6949999928474426\n",
      "Epoch 78, CIFAR-10 Batch 2:  \n",
      "Loss: 0.5065863728523254 accuracy: 0.8279703259468079\n",
      "\n",
      "Validation accuracy: 0.6949999928474426\n",
      "Epoch 78, CIFAR-10 Batch 3:  \n",
      "Loss: 0.4858381450176239 accuracy: 0.8304455280303955\n",
      "\n",
      "Validation accuracy: 0.6912000179290771\n",
      "Epoch 78, CIFAR-10 Batch 4:  \n",
      "Loss: 0.5039547681808472 accuracy: 0.8279703259468079\n",
      "\n",
      "Validation accuracy: 0.6830000281333923\n",
      "Epoch 78, CIFAR-10 Batch 5:  \n",
      "Loss: 0.46310845017433167 accuracy: 0.8477723002433777\n",
      "\n",
      "Validation accuracy: 0.6980000138282776\n",
      "Epoch 79, CIFAR-10 Batch 1:  \n",
      "Loss: 0.4945726692676544 accuracy: 0.8341584205627441\n",
      "\n",
      "Validation accuracy: 0.6937999725341797\n",
      "Epoch 79, CIFAR-10 Batch 2:  \n",
      "Loss: 0.511326789855957 accuracy: 0.8353960514068604\n",
      "\n",
      "Validation accuracy: 0.6876000165939331\n",
      "Epoch 79, CIFAR-10 Batch 3:  \n",
      "Loss: 0.45883259177207947 accuracy: 0.8415841460227966\n",
      "\n",
      "Validation accuracy: 0.6913999915122986\n",
      "Epoch 79, CIFAR-10 Batch 4:  \n",
      "Loss: 0.5024953484535217 accuracy: 0.8279703259468079\n",
      "\n",
      "Validation accuracy: 0.6926000118255615\n",
      "Epoch 79, CIFAR-10 Batch 5:  \n",
      "Loss: 0.4672802984714508 accuracy: 0.8415841460227966\n",
      "\n",
      "Validation accuracy: 0.6941999793052673\n",
      "Epoch 80, CIFAR-10 Batch 1:  \n",
      "Loss: 0.5006539225578308 accuracy: 0.8378713130950928\n",
      "\n",
      "Validation accuracy: 0.6881999969482422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80, CIFAR-10 Batch 2:  \n",
      "Loss: 0.4986169636249542 accuracy: 0.8353960514068604\n",
      "\n",
      "Validation accuracy: 0.6905999779701233\n",
      "Epoch 80, CIFAR-10 Batch 3:  \n",
      "Loss: 0.4725671410560608 accuracy: 0.844059407711029\n",
      "\n",
      "Validation accuracy: 0.6904000043869019\n",
      "Epoch 80, CIFAR-10 Batch 4:  \n",
      "Loss: 0.5111152529716492 accuracy: 0.8267326951026917\n",
      "\n",
      "Validation accuracy: 0.6826000213623047\n",
      "Epoch 80, CIFAR-10 Batch 5:  \n",
      "Loss: 0.48283299803733826 accuracy: 0.8415841460227966\n",
      "\n",
      "Validation accuracy: 0.6912000179290771\n",
      "Epoch 81, CIFAR-10 Batch 1:  \n",
      "Loss: 0.5073583126068115 accuracy: 0.8452970385551453\n",
      "\n",
      "Validation accuracy: 0.6880000233650208\n",
      "Epoch 81, CIFAR-10 Batch 2:  \n",
      "Loss: 0.5077890157699585 accuracy: 0.8180692791938782\n",
      "\n",
      "Validation accuracy: 0.6922000050544739\n",
      "Epoch 81, CIFAR-10 Batch 3:  \n",
      "Loss: 0.4683327376842499 accuracy: 0.844059407711029\n",
      "\n",
      "Validation accuracy: 0.6909999847412109\n",
      "Epoch 81, CIFAR-10 Batch 4:  \n",
      "Loss: 0.5118169784545898 accuracy: 0.8279703259468079\n",
      "\n",
      "Validation accuracy: 0.6877999901771545\n",
      "Epoch 81, CIFAR-10 Batch 5:  \n",
      "Loss: 0.4628530740737915 accuracy: 0.853960394859314\n",
      "\n",
      "Validation accuracy: 0.6952000260353088\n",
      "Epoch 82, CIFAR-10 Batch 1:  \n",
      "Loss: 0.4780413508415222 accuracy: 0.844059407711029\n",
      "\n",
      "Validation accuracy: 0.6931999921798706\n",
      "Epoch 82, CIFAR-10 Batch 2:  \n",
      "Loss: 0.4954253137111664 accuracy: 0.8279703259468079\n",
      "\n",
      "Validation accuracy: 0.6931999921798706\n",
      "Epoch 82, CIFAR-10 Batch 3:  \n",
      "Loss: 0.4722534418106079 accuracy: 0.8366336822509766\n",
      "\n",
      "Validation accuracy: 0.6800000071525574\n",
      "Epoch 82, CIFAR-10 Batch 4:  \n",
      "Loss: 0.4906969666481018 accuracy: 0.844059407711029\n",
      "\n",
      "Validation accuracy: 0.6916000247001648\n",
      "Epoch 82, CIFAR-10 Batch 5:  \n",
      "Loss: 0.4631540775299072 accuracy: 0.8403465151786804\n",
      "\n",
      "Validation accuracy: 0.6858000159263611\n",
      "Epoch 83, CIFAR-10 Batch 1:  \n",
      "Loss: 0.46412554383277893 accuracy: 0.853960394859314\n",
      "\n",
      "Validation accuracy: 0.6959999799728394\n",
      "Epoch 83, CIFAR-10 Batch 2:  \n",
      "Loss: 0.4945187568664551 accuracy: 0.8254950642585754\n",
      "\n",
      "Validation accuracy: 0.692799985408783\n",
      "Epoch 83, CIFAR-10 Batch 3:  \n",
      "Loss: 0.4496749937534332 accuracy: 0.8477723002433777\n",
      "\n",
      "Validation accuracy: 0.6851999759674072\n",
      "Epoch 83, CIFAR-10 Batch 4:  \n",
      "Loss: 0.48381203413009644 accuracy: 0.8428217768669128\n",
      "\n",
      "Validation accuracy: 0.6887999773025513\n",
      "Epoch 83, CIFAR-10 Batch 5:  \n",
      "Loss: 0.45412784814834595 accuracy: 0.8502475023269653\n",
      "\n",
      "Validation accuracy: 0.6944000124931335\n",
      "Epoch 84, CIFAR-10 Batch 1:  \n",
      "Loss: 0.48007115721702576 accuracy: 0.844059407711029\n",
      "\n",
      "Validation accuracy: 0.6883999705314636\n",
      "Epoch 84, CIFAR-10 Batch 2:  \n",
      "Loss: 0.497359961271286 accuracy: 0.844059407711029\n",
      "\n",
      "Validation accuracy: 0.692799985408783\n",
      "Epoch 84, CIFAR-10 Batch 3:  \n",
      "Loss: 0.46446332335472107 accuracy: 0.8428217768669128\n",
      "\n",
      "Validation accuracy: 0.6826000213623047\n",
      "Epoch 84, CIFAR-10 Batch 4:  \n",
      "Loss: 0.5019043684005737 accuracy: 0.8403465151786804\n",
      "\n",
      "Validation accuracy: 0.6863999962806702\n",
      "Epoch 84, CIFAR-10 Batch 5:  \n",
      "Loss: 0.44835165143013 accuracy: 0.8551980257034302\n",
      "\n",
      "Validation accuracy: 0.6931999921798706\n",
      "Epoch 85, CIFAR-10 Batch 1:  \n",
      "Loss: 0.45950397849082947 accuracy: 0.8514851331710815\n",
      "\n",
      "Validation accuracy: 0.6972000002861023\n",
      "Epoch 85, CIFAR-10 Batch 2:  \n",
      "Loss: 0.4771607220172882 accuracy: 0.8329207897186279\n",
      "\n",
      "Validation accuracy: 0.6940000057220459\n",
      "Epoch 85, CIFAR-10 Batch 3:  \n",
      "Loss: 0.43819496035575867 accuracy: 0.8551980257034302\n",
      "\n",
      "Validation accuracy: 0.6873999834060669\n",
      "Epoch 85, CIFAR-10 Batch 4:  \n",
      "Loss: 0.4896927773952484 accuracy: 0.8366336822509766\n",
      "\n",
      "Validation accuracy: 0.6891999840736389\n",
      "Epoch 85, CIFAR-10 Batch 5:  \n",
      "Loss: 0.43893831968307495 accuracy: 0.8626237511634827\n",
      "\n",
      "Validation accuracy: 0.692799985408783\n",
      "Epoch 86, CIFAR-10 Batch 1:  \n",
      "Loss: 0.45291784405708313 accuracy: 0.8650990128517151\n",
      "\n",
      "Validation accuracy: 0.6862000226974487\n",
      "Epoch 86, CIFAR-10 Batch 2:  \n",
      "Loss: 0.47775915265083313 accuracy: 0.8415841460227966\n",
      "\n",
      "Validation accuracy: 0.6944000124931335\n",
      "Epoch 86, CIFAR-10 Batch 3:  \n",
      "Loss: 0.42855480313301086 accuracy: 0.8490098714828491\n",
      "\n",
      "Validation accuracy: 0.6890000104904175\n",
      "Epoch 86, CIFAR-10 Batch 4:  \n",
      "Loss: 0.4880540370941162 accuracy: 0.8502475023269653\n",
      "\n",
      "Validation accuracy: 0.6901999711990356\n",
      "Epoch 86, CIFAR-10 Batch 5:  \n",
      "Loss: 0.4204046428203583 accuracy: 0.8601484894752502\n",
      "\n",
      "Validation accuracy: 0.6909999847412109\n",
      "Epoch 87, CIFAR-10 Batch 1:  \n",
      "Loss: 0.4428011476993561 accuracy: 0.8576732873916626\n",
      "\n",
      "Validation accuracy: 0.6917999982833862\n",
      "Epoch 87, CIFAR-10 Batch 2:  \n",
      "Loss: 0.4724978804588318 accuracy: 0.8353960514068604\n",
      "\n",
      "Validation accuracy: 0.6967999935150146\n",
      "Epoch 87, CIFAR-10 Batch 3:  \n",
      "Loss: 0.42105063796043396 accuracy: 0.8576732873916626\n",
      "\n",
      "Validation accuracy: 0.6890000104904175\n",
      "Epoch 87, CIFAR-10 Batch 4:  \n",
      "Loss: 0.5015011429786682 accuracy: 0.8316831588745117\n",
      "\n",
      "Validation accuracy: 0.6881999969482422\n",
      "Epoch 87, CIFAR-10 Batch 5:  \n",
      "Loss: 0.4303683936595917 accuracy: 0.8650990128517151\n",
      "\n",
      "Validation accuracy: 0.6891999840736389\n",
      "Epoch 88, CIFAR-10 Batch 1:  \n",
      "Loss: 0.4530371427536011 accuracy: 0.8477723002433777\n",
      "\n",
      "Validation accuracy: 0.6905999779701233\n",
      "Epoch 88, CIFAR-10 Batch 2:  \n",
      "Loss: 0.47338518500328064 accuracy: 0.8477723002433777\n",
      "\n",
      "Validation accuracy: 0.6869999766349792\n",
      "Epoch 88, CIFAR-10 Batch 3:  \n",
      "Loss: 0.4138495624065399 accuracy: 0.8589109182357788\n",
      "\n",
      "Validation accuracy: 0.6890000104904175\n",
      "Epoch 88, CIFAR-10 Batch 4:  \n",
      "Loss: 0.48333287239074707 accuracy: 0.8465346693992615\n",
      "\n",
      "Validation accuracy: 0.6872000098228455\n",
      "Epoch 88, CIFAR-10 Batch 5:  \n",
      "Loss: 0.40765997767448425 accuracy: 0.8663366436958313\n",
      "\n",
      "Validation accuracy: 0.6959999799728394\n",
      "Epoch 89, CIFAR-10 Batch 1:  \n",
      "Loss: 0.4275323748588562 accuracy: 0.8663366436958313\n",
      "\n",
      "Validation accuracy: 0.6930000185966492\n",
      "Epoch 89, CIFAR-10 Batch 2:  \n",
      "Loss: 0.45135489106178284 accuracy: 0.8551980257034302\n",
      "\n",
      "Validation accuracy: 0.6937999725341797\n",
      "Epoch 89, CIFAR-10 Batch 3:  \n",
      "Loss: 0.4098964035511017 accuracy: 0.8650990128517151\n",
      "\n",
      "Validation accuracy: 0.6904000043869019\n",
      "Epoch 89, CIFAR-10 Batch 4:  \n",
      "Loss: 0.4969319999217987 accuracy: 0.8403465151786804\n",
      "\n",
      "Validation accuracy: 0.6868000030517578\n",
      "Epoch 89, CIFAR-10 Batch 5:  \n",
      "Loss: 0.40842846035957336 accuracy: 0.8613861203193665\n",
      "\n",
      "Validation accuracy: 0.6883999705314636\n",
      "Epoch 90, CIFAR-10 Batch 1:  \n",
      "Loss: 0.4289636015892029 accuracy: 0.8613861203193665\n",
      "\n",
      "Validation accuracy: 0.6980000138282776\n",
      "Epoch 90, CIFAR-10 Batch 2:  \n",
      "Loss: 0.4523466229438782 accuracy: 0.8551980257034302\n",
      "\n",
      "Validation accuracy: 0.696399986743927\n",
      "Epoch 90, CIFAR-10 Batch 3:  \n",
      "Loss: 0.4059916138648987 accuracy: 0.8626237511634827\n",
      "\n",
      "Validation accuracy: 0.6922000050544739\n",
      "Epoch 90, CIFAR-10 Batch 4:  \n",
      "Loss: 0.4711604416370392 accuracy: 0.8341584205627441\n",
      "\n",
      "Validation accuracy: 0.6863999962806702\n",
      "Epoch 90, CIFAR-10 Batch 5:  \n",
      "Loss: 0.4081394374370575 accuracy: 0.8700494766235352\n",
      "\n",
      "Validation accuracy: 0.6895999908447266\n",
      "Epoch 91, CIFAR-10 Batch 1:  \n",
      "Loss: 0.42487218976020813 accuracy: 0.8576732873916626\n",
      "\n",
      "Validation accuracy: 0.6952000260353088\n",
      "Epoch 91, CIFAR-10 Batch 2:  \n",
      "Loss: 0.45962485671043396 accuracy: 0.8452970385551453\n",
      "\n",
      "Validation accuracy: 0.6881999969482422\n",
      "Epoch 91, CIFAR-10 Batch 3:  \n",
      "Loss: 0.42118722200393677 accuracy: 0.8589109182357788\n",
      "\n",
      "Validation accuracy: 0.6898000240325928\n",
      "Epoch 91, CIFAR-10 Batch 4:  \n",
      "Loss: 0.4499220550060272 accuracy: 0.8589109182357788\n",
      "\n",
      "Validation accuracy: 0.6966000199317932\n",
      "Epoch 91, CIFAR-10 Batch 5:  \n",
      "Loss: 0.40334513783454895 accuracy: 0.8688119053840637\n",
      "\n",
      "Validation accuracy: 0.6850000023841858\n",
      "Epoch 92, CIFAR-10 Batch 1:  \n",
      "Loss: 0.4432774484157562 accuracy: 0.8626237511634827\n",
      "\n",
      "Validation accuracy: 0.6887999773025513\n",
      "Epoch 92, CIFAR-10 Batch 2:  \n",
      "Loss: 0.4535004198551178 accuracy: 0.8551980257034302\n",
      "\n",
      "Validation accuracy: 0.692799985408783\n",
      "Epoch 92, CIFAR-10 Batch 3:  \n",
      "Loss: 0.4000668227672577 accuracy: 0.8589109182357788\n",
      "\n",
      "Validation accuracy: 0.6909999847412109\n",
      "Epoch 92, CIFAR-10 Batch 4:  \n",
      "Loss: 0.4359988868236542 accuracy: 0.8700494766235352\n",
      "\n",
      "Validation accuracy: 0.6991999745368958\n",
      "Epoch 92, CIFAR-10 Batch 5:  \n",
      "Loss: 0.39657315611839294 accuracy: 0.8688119053840637\n",
      "\n",
      "Validation accuracy: 0.6940000057220459\n",
      "Epoch 93, CIFAR-10 Batch 1:  \n",
      "Loss: 0.42828837037086487 accuracy: 0.8638613820075989\n",
      "\n",
      "Validation accuracy: 0.6859999895095825\n",
      "Epoch 93, CIFAR-10 Batch 2:  \n",
      "Loss: 0.43960583209991455 accuracy: 0.8700494766235352\n",
      "\n",
      "Validation accuracy: 0.6934000253677368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93, CIFAR-10 Batch 3:  \n",
      "Loss: 0.38502153754234314 accuracy: 0.8700494766235352\n",
      "\n",
      "Validation accuracy: 0.6941999793052673\n",
      "Epoch 93, CIFAR-10 Batch 4:  \n",
      "Loss: 0.449262797832489 accuracy: 0.8601484894752502\n",
      "\n",
      "Validation accuracy: 0.6934000253677368\n",
      "Epoch 93, CIFAR-10 Batch 5:  \n",
      "Loss: 0.40479037165641785 accuracy: 0.8626237511634827\n",
      "\n",
      "Validation accuracy: 0.6901999711990356\n",
      "Epoch 94, CIFAR-10 Batch 1:  \n",
      "Loss: 0.4272296130657196 accuracy: 0.8663366436958313\n",
      "\n",
      "Validation accuracy: 0.6890000104904175\n",
      "Epoch 94, CIFAR-10 Batch 2:  \n",
      "Loss: 0.4490644931793213 accuracy: 0.8502475023269653\n",
      "\n",
      "Validation accuracy: 0.6895999908447266\n",
      "Epoch 94, CIFAR-10 Batch 3:  \n",
      "Loss: 0.40217143297195435 accuracy: 0.8564356565475464\n",
      "\n",
      "Validation accuracy: 0.6881999969482422\n",
      "Epoch 94, CIFAR-10 Batch 4:  \n",
      "Loss: 0.43658456206321716 accuracy: 0.8663366436958313\n",
      "\n",
      "Validation accuracy: 0.6980000138282776\n",
      "Epoch 94, CIFAR-10 Batch 5:  \n",
      "Loss: 0.3900461494922638 accuracy: 0.8762376308441162\n",
      "\n",
      "Validation accuracy: 0.6984000205993652\n",
      "Epoch 95, CIFAR-10 Batch 1:  \n",
      "Loss: 0.4144192636013031 accuracy: 0.8688119053840637\n",
      "\n",
      "Validation accuracy: 0.6919999718666077\n",
      "Epoch 95, CIFAR-10 Batch 2:  \n",
      "Loss: 0.4415209889411926 accuracy: 0.8564356565475464\n",
      "\n",
      "Validation accuracy: 0.6926000118255615\n",
      "Epoch 95, CIFAR-10 Batch 3:  \n",
      "Loss: 0.3993281424045563 accuracy: 0.8712871074676514\n",
      "\n",
      "Validation accuracy: 0.6880000233650208\n",
      "Epoch 95, CIFAR-10 Batch 4:  \n",
      "Loss: 0.45210355520248413 accuracy: 0.8564356565475464\n",
      "\n",
      "Validation accuracy: 0.6908000111579895\n",
      "Epoch 95, CIFAR-10 Batch 5:  \n",
      "Loss: 0.39931371808052063 accuracy: 0.8688119053840637\n",
      "\n",
      "Validation accuracy: 0.6988000273704529\n",
      "Epoch 96, CIFAR-10 Batch 1:  \n",
      "Loss: 0.4107612073421478 accuracy: 0.8799505233764648\n",
      "\n",
      "Validation accuracy: 0.6895999908447266\n",
      "Epoch 96, CIFAR-10 Batch 2:  \n",
      "Loss: 0.44154566526412964 accuracy: 0.8576732873916626\n",
      "\n",
      "Validation accuracy: 0.6955999732017517\n",
      "Epoch 96, CIFAR-10 Batch 3:  \n",
      "Loss: 0.39504677057266235 accuracy: 0.8737623691558838\n",
      "\n",
      "Validation accuracy: 0.6863999962806702\n",
      "Epoch 96, CIFAR-10 Batch 4:  \n",
      "Loss: 0.4460388720035553 accuracy: 0.8601484894752502\n",
      "\n",
      "Validation accuracy: 0.6905999779701233\n",
      "Epoch 96, CIFAR-10 Batch 5:  \n",
      "Loss: 0.40441226959228516 accuracy: 0.8650990128517151\n",
      "\n",
      "Validation accuracy: 0.6899999976158142\n",
      "Epoch 97, CIFAR-10 Batch 1:  \n",
      "Loss: 0.41810935735702515 accuracy: 0.8774752616882324\n",
      "\n",
      "Validation accuracy: 0.6919999718666077\n",
      "Epoch 97, CIFAR-10 Batch 2:  \n",
      "Loss: 0.45677486062049866 accuracy: 0.8490098714828491\n",
      "\n",
      "Validation accuracy: 0.6904000043869019\n",
      "Epoch 97, CIFAR-10 Batch 3:  \n",
      "Loss: 0.3742503225803375 accuracy: 0.8737623691558838\n",
      "\n",
      "Validation accuracy: 0.6941999793052673\n",
      "Epoch 97, CIFAR-10 Batch 4:  \n",
      "Loss: 0.43925565481185913 accuracy: 0.8601484894752502\n",
      "\n",
      "Validation accuracy: 0.6905999779701233\n",
      "Epoch 97, CIFAR-10 Batch 5:  \n",
      "Loss: 0.4006664454936981 accuracy: 0.8601484894752502\n",
      "\n",
      "Validation accuracy: 0.6862000226974487\n",
      "Epoch 98, CIFAR-10 Batch 1:  \n",
      "Loss: 0.39811334013938904 accuracy: 0.8737623691558838\n",
      "\n",
      "Validation accuracy: 0.6973999738693237\n",
      "Epoch 98, CIFAR-10 Batch 2:  \n",
      "Loss: 0.44644322991371155 accuracy: 0.8613861203193665\n",
      "\n",
      "Validation accuracy: 0.692799985408783\n",
      "Epoch 98, CIFAR-10 Batch 3:  \n",
      "Loss: 0.3822806477546692 accuracy: 0.8725247383117676\n",
      "\n",
      "Validation accuracy: 0.6952000260353088\n",
      "Epoch 98, CIFAR-10 Batch 4:  \n",
      "Loss: 0.45448359847068787 accuracy: 0.8613861203193665\n",
      "\n",
      "Validation accuracy: 0.6891999840736389\n",
      "Epoch 98, CIFAR-10 Batch 5:  \n",
      "Loss: 0.40570497512817383 accuracy: 0.8638613820075989\n",
      "\n",
      "Validation accuracy: 0.680400013923645\n",
      "Epoch 99, CIFAR-10 Batch 1:  \n",
      "Loss: 0.40227216482162476 accuracy: 0.8774752616882324\n",
      "\n",
      "Validation accuracy: 0.6998000144958496\n",
      "Epoch 99, CIFAR-10 Batch 2:  \n",
      "Loss: 0.4490054249763489 accuracy: 0.8626237511634827\n",
      "\n",
      "Validation accuracy: 0.6891999840736389\n",
      "Epoch 99, CIFAR-10 Batch 3:  \n",
      "Loss: 0.4025017321109772 accuracy: 0.8564356565475464\n",
      "\n",
      "Validation accuracy: 0.6905999779701233\n",
      "Epoch 99, CIFAR-10 Batch 4:  \n",
      "Loss: 0.4404720962047577 accuracy: 0.8626237511634827\n",
      "\n",
      "Validation accuracy: 0.6941999793052673\n",
      "Epoch 99, CIFAR-10 Batch 5:  \n",
      "Loss: 0.38261550664901733 accuracy: 0.8787128925323486\n",
      "\n",
      "Validation accuracy: 0.6836000084877014\n",
      "Epoch 100, CIFAR-10 Batch 1:  \n",
      "Loss: 0.40942835807800293 accuracy: 0.8700494766235352\n",
      "\n",
      "Validation accuracy: 0.6887999773025513\n",
      "Epoch 100, CIFAR-10 Batch 2:  \n",
      "Loss: 0.45935767889022827 accuracy: 0.8502475023269653\n",
      "\n",
      "Validation accuracy: 0.6837999820709229\n",
      "Epoch 100, CIFAR-10 Batch 3:  \n",
      "Loss: 0.384650856256485 accuracy: 0.8675742745399475\n",
      "\n",
      "Validation accuracy: 0.6966000199317932\n",
      "Epoch 100, CIFAR-10 Batch 4:  \n",
      "Loss: 0.4209412634372711 accuracy: 0.8762376308441162\n",
      "\n",
      "Validation accuracy: 0.7006000280380249\n",
      "Epoch 100, CIFAR-10 Batch 5:  \n",
      "Loss: 0.374479740858078 accuracy: 0.8811880946159363\n",
      "\n",
      "Validation accuracy: 0.6881999969482422\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "save_model_path = './image_classification'\n",
    "\n",
    "print('Training...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        # Loop over all batches\n",
    "        n_batches = 5\n",
    "        for batch_i in range(1, n_batches + 1):\n",
    "            for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "                train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "            print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "            print_stats(sess, batch_features, batch_labels, cost, accuracy)\n",
    "            \n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, save_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoint\n",
    "The model has been saved to disk.\n",
    "## Test Model\n",
    "Test your model against the test dataset.  This will be your final accuracy. You should have an accuracy greater than 50%. If you don't, keep tweaking the model architecture and parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./image_classification\n",
      "Testing Accuracy: 0.692010122537613\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAscAAAJ/CAYAAACUb342AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFdz5yqEubUAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x229c268d860>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 319,
       "width": 355
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import helper\n",
    "import random\n",
    "\n",
    "# Set batch size if not already set\n",
    "try:\n",
    "    if batch_size:\n",
    "        pass\n",
    "except NameError:\n",
    "    batch_size = 64\n",
    "\n",
    "save_model_path = './image_classification'\n",
    "n_samples = 4\n",
    "top_n_predictions = 3\n",
    "\n",
    "def test_model():\n",
    "    \"\"\"\n",
    "    Test the saved model against the test dataset\n",
    "    \"\"\"\n",
    "\n",
    "    test_features, test_labels = pickle.load(open('preprocess_test.p', mode='rb'))\n",
    "    loaded_graph = tf.Graph()\n",
    "\n",
    "    with tf.Session(graph=loaded_graph) as sess:\n",
    "        # Load model\n",
    "        loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
    "        loader.restore(sess, save_model_path)\n",
    "\n",
    "        # Get Tensors from loaded model\n",
    "        loaded_x = loaded_graph.get_tensor_by_name('x:0')\n",
    "        loaded_y = loaded_graph.get_tensor_by_name('y:0')\n",
    "        loaded_keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "        loaded_logits = loaded_graph.get_tensor_by_name('logits:0')\n",
    "        loaded_acc = loaded_graph.get_tensor_by_name('accuracy:0')\n",
    "        \n",
    "        # Get accuracy in batches for memory limitations\n",
    "        test_batch_acc_total = 0\n",
    "        test_batch_count = 0\n",
    "        \n",
    "        for test_feature_batch, test_label_batch in helper.batch_features_labels(test_features, test_labels, batch_size):\n",
    "            test_batch_acc_total += sess.run(\n",
    "                loaded_acc,\n",
    "                feed_dict={loaded_x: test_feature_batch, loaded_y: test_label_batch, loaded_keep_prob: 1.0})\n",
    "            test_batch_count += 1\n",
    "\n",
    "        print('Testing Accuracy: {}\\n'.format(test_batch_acc_total/test_batch_count))\n",
    "\n",
    "        # Print Random Samples\n",
    "        random_test_features, random_test_labels = tuple(zip(*random.sample(list(zip(test_features, test_labels)), n_samples)))\n",
    "        random_test_predictions = sess.run(\n",
    "            tf.nn.top_k(tf.nn.softmax(loaded_logits), top_n_predictions),\n",
    "            feed_dict={loaded_x: random_test_features, loaded_y: random_test_labels, loaded_keep_prob: 1.0})\n",
    "        helper.display_image_predictions(random_test_features, random_test_labels, random_test_predictions)\n",
    "\n",
    "\n",
    "test_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why 50-80% Accuracy?\n",
    "You might be wondering why you can't get an accuracy any higher. First things first, 50% isn't bad for a simple CNN.  Pure guessing would get you 10% accuracy. However, you might notice people are getting scores [well above 80%](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#43494641522d3130).  That's because we haven't taught you all there is to know about neural networks. We still need to cover a few more techniques.\n",
    "## Submitting This Project\n",
    "When submitting this project, make sure to run all the cells before saving the notebook.  Save the notebook file as \"dlnd_image_classification.ipynb\" and save it as a HTML file under \"File\" -> \"Download as\".  Include the \"helper.py\" and \"problem_unittests.py\" files in your submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
